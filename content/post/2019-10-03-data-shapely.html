---
title: Data Shapely
author: Muhammad Chenariyan Nakhaee
date: '2019-10-03'
slug: data-shapely
categories: []
tags:
  - XAI
subtitle: ''
summary: ''
authors: []
lastmod: '2019-10-03T14:43:44+02:00'
featured: no
draft: TRUE 
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="what-is-your-data-worth-equitable-data-valuation-in-machine-learning" class="section level1">
<h1>What is Your Data Worth? Equitable Data Valuation in Machine Learning</h1>
<p>This paper barely mentions the term explainability although it is closely related to this domain. Actually the motivation behind this paper is not that we want to know the impact individual points on the performance of machine learning models and detect potential bias present in the dataset. On the other hand,the motivat</p>
<p>The basic idea behind this paper is that we want to measure and quantify the value of individual data points.</p>
<p>One motivation behind that is</p>
<p>data value must be computed with respect to three ingridients:</p>
<p>A fixed training dataset: If we use a different subset of data for training, it will be likely that the results of our machine learning model would change.</p>
<p>the machine learning model:</p>
<p>the performance metric: imagin we would like to classify benign and … tumors in a highly imbalanced dataset. If we use accuracy as the performance metric the impact that each data point have on this metric is small. However, if we use a different metric such as percision, the impact of individual points from minority class which were classified incorrectly as … on this metric will be significant.</p>
<div id="influence-functions" class="section level3">
<h3>influence functions</h3>
<p>While influence function do not take into account</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<div id="motivation" class="section level4">
<h4><strong>Motivation</strong></h4>
<p>We want to measure the (equitable) value of data (samples) in terms of their contribution to the model training, prediction and decision making.</p>
<p>{{&lt; figure library=“true” src=“3ingridients.jpg” title=“A caption” lightbox=“true” &gt;}}</p>
<p><img src="/content/post/3ingridients.jpg" /></p>
<p>Supervised ML models consist of three ingredients:</p>
<p>· Training data</p>
<p>· Learning model</p>
<p>· Performance metrics</p>
<p>Therefore, quantifying Data value should reflect all of these ingredients because in some algorithms the value of a data point might change based on the algorithm or the metric that we use.</p>
</div>
<div id="research-questions" class="section level4">
<h4><strong>Research Questions</strong></h4>
<p>In this paper the following two research questions were addressed;</p>
<ol style="list-style-type: decimal">
<li>what is an equitable measure of value of a data point to the machine learning model with respect to the performance metric</li>
<li>How to measure these data values efficiently?</li>
</ol>
<p><strong>Similar approaches</strong></p>
<p>· Leave one out (LOO)</p>
<p>· Influence functions</p>
</div>
<div id="idea" class="section level4">
<h4><strong>Idea</strong></h4>
<p>They propose Data Shapely as a metric to measure the value (contribution) of individual data points to an algorithm’s performance.</p>
<p>Note that here data valuation is only defined and measurable in terms of supervised machine learning models.</p>
<div id="computing-data-shapely" class="section level5">
<h5>Computing Data Shapely</h5>
<p>Equitable data valuation has three main properties:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Null element</strong>: – If adding a sample to any subset of training data never changes the classifier performance, the value of the sample is 0</p>
<p><strong>Symmetry:</strong> – If adding i and j to any subset of training data always gives the same performance, then value of data i and j are the same</p></li>
<li><p><strong>Decomposability</strong> – the overall performance score is the sum of individual performance scores</p></li>
</ol>
<p>Based on the condition above Data Shapely are computed:</p>
<p>{to do : add formula 1}</p>
<p>However, computing this formula is computationally expensive as each time that we add a data point to a subset we have to train the machine learning model.</p>
<p>Therefore, the authors tried to approximate this value by some smart techniques.</p>
</div>
</div>
<div id="evaluation" class="section level4">
<h4><strong>Evaluation</strong></h4>
<div id="datasets" class="section level5">
<h5><strong>Datasets</strong></h5>
<ul>
<li>UK Biobank data set (Tabular)</li>
<li>HAM10000 dataset (image)</li>
</ul>
<p><strong>Results</strong></p>
<p>·Removing data points with the <strong>lowest</strong> Shapely valued improves the model performance</p>
<p>· Removing data points with the <strong>highest</strong> Shapely values decreases the model performance</p>
<p><strong>Main Applications:</strong></p>
<ul>
<li>Better allocate our resources for collecting data points that are similar to data points with high Shapely values.</li>
<li>Measure the value of data samples that we already have</li>
<li>Can be used as a diagnosis tool to identify mislabeled data points.</li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li>No condition on it optimality</li>
<li>It was not compared with other powerful techniques such as influence functions.</li>
<li>Motivation behind the paper is problematic (Data = new oil)</li>
<li>Measuring individual data values in the context of legal domains is different from machine learning domains so they will not achieve the goal that they set in the motivation with this technique</li>
</ul>
<p><strong>Advantages</strong></p>
<ul>
<li><p>Data value is computed based on all ingredients of machine learning pipeline.</p></li>
<li><p>Computing Shapely values is not limited by the type of data, model and performance metrics.
## Resources
Official Repository for the paper:
<a href="https://github.com/amiratag/DataShapley" class="uri">https://github.com/amiratag/DataShapley</a></p></li>
<li><p><a href="https://www.youtube.com/watch?v=79pRqMq_-LE">A talk by one of the authors</a></p></li>
<li><p><a href="https://blog.acolyer.org/2019/07/15/data-shapley/">A blog post explaining and summarizing the paper</a></p></li>
<li><p><a href="http://lineardigressions.com/episodes/2018/5/6/game-theory-for-model-interpretability-shapley-values">A podcast episode about Data Shapely</a></p></li>
</ul>
</div>
</div>
</div>
</div>
