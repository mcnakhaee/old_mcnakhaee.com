---
title: An R Markdown document converted from "test.ipynb"
output: html_document
---



<pre class="python"><code>import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split</code></pre>
<pre class="python"><code>titanic = pd.read_csv(&#39;titanic_train.csv&#39;)
titanic.head()</code></pre>
<pre><code>##    PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
## 0            1         0       3  ...   7.2500   NaN         S
## 1            2         1       1  ...  71.2833   C85         C
## 2            3         1       3  ...   7.9250   NaN         S
## 3            4         1       1  ...  53.1000  C123         S
## 4            5         0       3  ...   8.0500   NaN         S
## 
## [5 rows x 12 columns]</code></pre>
<pre class="python"><code>def sex_binary(x):
  if x == &#39;male&#39;:
    return 0 
  else:
    return 1
titanic_dummified = pd.get_dummies(titanic,columns=[&#39;Embarked&#39;])
titanic_dummified[&#39;Sex_binary&#39;] = titanic_dummified[&#39;Sex&#39;].apply(lambda x:sex_binary(x) )
titanic_dummified.drop([&#39;Cabin&#39;,&#39;Ticket&#39;,&#39;Name&#39;,&#39;Sex&#39;],axis = 1,inplace=True)
titanic_dummified.head()</code></pre>
<pre><code>##    PassengerId  Survived  Pclass  ...  Embarked_Q  Embarked_S  Sex_binary
## 0            1         0       3  ...           0           1           0
## 1            2         1       1  ...           0           0           1
## 2            3         1       3  ...           0           1           1
## 3            4         1       1  ...           0           1           1
## 4            5         0       3  ...           0           1           0
## 
## [5 rows x 11 columns]</code></pre>
<pre class="python"><code>titanic_dummified.shape</code></pre>
<pre><code>## (891, 11)</code></pre>
<pre class="python"><code>titanic_dummified = titanic_dummified.dropna()
titanic_dummified.isna().sum()</code></pre>
<pre><code>## PassengerId    0
## Survived       0
## Pclass         0
## Age            0
## SibSp          0
## Parch          0
## Fare           0
## Embarked_C     0
## Embarked_Q     0
## Embarked_S     0
## Sex_binary     0
## dtype: int64</code></pre>
<pre class="python"><code>X = titanic_dummified.drop([&#39;Survived&#39;],axis=1)
y = titanic_dummified[&#39;Survived&#39;]
train, test, labels_train, labels_test = train_test_split(X, y, train_size=0.80)</code></pre>
<pre class="python"><code>rf = RandomForestClassifier(n_estimators=100)
rf.fit(train,labels_train)</code></pre>
<pre><code>## RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
##                        max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
##                        min_impurity_decrease=0.0, min_impurity_split=None,
##                        min_samples_leaf=1, min_samples_split=2,
##                        min_weight_fraction_leaf=0.0, n_estimators=100,
##                        n_jobs=None, oob_score=False, random_state=None,
##                        verbose=0, warm_start=False)</code></pre>
<pre class="python"><code>rf.score(test,labels_test)</code></pre>
<pre><code>## 0.8461538461538461</code></pre>
<pre class="python"><code>prd_ds = test.copy()
prd_ds[&#39;actual&#39;]  = labels_test
prd_ds[&#39;prds&#39;] = rf.predict(test)

prd_ds[&#39;wrong&#39;]  =  prd_ds[&#39;prds&#39;] == prd_ds[&#39;actual&#39;]</code></pre>
<pre class="python"><code>import lime
import lime.lime_tabular
import dtreeviz
import shap</code></pre>
<pre class="python"><code>explainer = lime.lime_tabular.LimeTabularExplainer(
train.to_numpy(),
feature_names = list(train.columns),
class_names = [0,1],
discretize_continuous = True
)</code></pre>
<pre class="python"><code>instance = test.iloc[1,:]
exp = explainer.explain_instance(instance,
rf.predict_proba,
num_features = 5,
top_labels = 1
)</code></pre>
<pre class="python"><code>exp.show_in_notebook(show_table = True,show_all = True)</code></pre>
<pre><code>## &lt;IPython.core.display.HTML object&gt;</code></pre>
