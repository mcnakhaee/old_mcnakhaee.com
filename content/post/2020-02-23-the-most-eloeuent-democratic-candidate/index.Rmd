---
title: "Who Is the Most Eloquent Democratic Candidate in Debates?"
author: Muhammad Chenariyan Nakhaee
date: '2020-02-23'
slug: []
categories:
  - NLP
  - R
tags:
  - NLP
  - R
subtitle: ''
summary: ''
authors: []
lastmod: '2020-02-23T17:15:22+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


```{r eval=FALSE, warning=TRUE, include=FALSE}
#devtools::install_github("favstats/demdebates2020")
#install.packages('ggthemes')  
 ggthemes::ggthemes_data[["tableau"]][["color-palettes"]][["regular"]] 
extrafont::font_install(
)
extrafont::font_import()
extrafont::loadfonts()
extrafont::font_install(fontpkg = 'alegreya')
```

I am not neither a US citizen nor have I not been to the US in my entire life. However, the US presidential election plays an important role in my life and almost everyone's else around the world. For that reason, I have been following the US politics very closely for a few years.

A few days ago I found [an R package](https://github.com/favstats/demdebates2020) on Twitter that contains the transcripts of the Democratic debates. Then I wondered how I can use my data science techniques to analyze these transcripts.

Everyone agrees that Donald Trump only uses a basic English vocabulary in his speeches and  tweets and probably he is not the most eloquent president in the US history. But what about his possible future challengers from the democratic party and how skillful  his opponents are with words? So, I decided to analyze transcripts from this aspected an identify how eloquent Trump's contenders are.

An eloquent person has acquired a rich vocabulary and uses a wide range of complex words in his/her speeches. On the other hand, an inarticulate person has a limited vocabulary and mainly uses simple and everyday words. So,Ideally, I think we can measure eloquency by counting the number of unique words and the number of sophisticated words that a person uses. 

However, I could  not find a dataset of English words along with their perceived complexity. So, to measure the eloquency of the presidential candidates, I defined two other metrics that I hope can serve as apporoximation to the truth:

1. **Vocabulary size**: The ratio of unique words that a candidate used in his/her debate speech.

2. **Vocabulary complexity**: The ratio of stop-words (words that are very common and usually don't add much value to the content).A lower ratio of stopword usage by a candidate indicates that the candidate is more articulate. 

I use the ``Tidytext`` library and its stopword list to compute my defined metrics.


```{r message=FALSE, warning=FALSE}
library(demdebates2020)
library(tidytext)
library(tidyverse)
library(gghighlight)
library(ggthemes)
theme_set(theme_fivethirtyeight())
theme_update(legend.position = 'none',
             text = element_text(family = 'Montserrat'),
      plot.title = element_text(family = 'Montserrat', face = "bold",size = 25, margin = margin(0, 0, 20, 0)),
      axis.text.x = element_blank(),
      axis.text.y = element_text(family = 'Montserrat', face = "bold",size = 15, margin = margin(0, 0, 20, 0)),
      
      panel.spacing = unit(2, "points"),)
```


I should mention that for the sake of simplicity, I only anlayze speeches delviered by candidates who are still in the race and were present in the 9th democratic debate.

```{r}
speakers <- debates %>%
  filter(!is.na(speech), type == 'Candidate' ,debate == 9) %>%
  distinct(speaker) %>%
  pull(speaker)
speakers
```

 But first the debate transcripts should be truned into a tidy format (one word per row). Then, I create a logical variable to see whether a words is a stopword or not.

```{r}
debate_vocab_df <- debates %>%
  filter(!is.na(speech), type == 'Candidate',speaker %in% speakers) %>%
  unnest_tokens(word, speech) %>%
  mutate(is_stop_word = word %in% stop_words$word) %>%
  group_by(speaker) %>%
  summarize(stop_word_ratio = sum(is_stop_word) / n(),
            vocab_size = n_distinct(word)/ n())  %>% 
  arrange(stop_word_ratio) 
  
head(debate_vocab_df)  
  
```

Now it is time to visualize the results using the ``ggplot`` library.

```{r fig.height=7, fig.width= 14, message=FALSE, warning=FALSE}
custom_palette <-
  c(
    'Mike Bloomberg' = '#EDC948',
    'Amy Klobuchar' = '#59A14F' ,
    'Joe Biden' = '#4E79A7',
    'Pete Buttigieg' = '#B07AA1',
    'Elizabeth Warren' =  '#F28E2B',
    'Bernie Sanders' = '#E15759' 
  )

'#76B7B2'
debate_vocab_df %>%
  mutate(speaker = fct_reorder(speaker,stop_word_ratio,.desc =  TRUE)) %>% 
  ggplot(aes(x = speaker , y = stop_word_ratio,fill = speaker)) +
  geom_col(show.legend = FALSE) +
  geom_label(aes(label = round(stop_word_ratio,digits = 3)) ,size = 5) +
  coord_flip() +
  scale_fill_manual(values = custom_palette) +
  labs(title = "The ratio of stopwords used by Democratic canidates in the debates")


```

It seems that so far Bernie Sanders has used the lowest percentage of stopwords in his speeches. On the other hand, Mike Bloomberg used the largest ratio of stopwords in his first and only debate.

The vocabulary size  measure shows a different trend as Mike Bloomberg has the highest score among the rest of the candidates. Of course, as I mentioned before, Bloomberg has appeared only once on the debate stage and it might be too soon to draw a conclusion about his eloquency.

```{r, fig.height = 7, fig.width = 15, message=FALSE, warning=FALSE}
 debate_vocab_df %>%
  mutate(speaker = fct_reorder(speaker,vocab_size,.desc =  TRUE)) %>% 
  ggplot(aes(x = speaker , y = vocab_size,fill = speaker)) +
  geom_col(show.legend = FALSE) +
  geom_label(aes(label = round(vocab_size,digits = 3) ,size = 8)) +
  coord_flip() +
  scale_fill_manual(values = custom_palette) +
  labs(title = "The ratio of unique Words used by Democratic candidates in the Debates",
       caption = 'Visualization: @m_cnakhaee\n\n Source: https://github.com/favstats/demdebates2020')


```


In conclusion, there is no outright winner in terms of language skills among Democratic candidates. Bernie Sanders got the best score in terms of vocabulary complexity but he has the least ratio of unique words among his competitors. Also, one can argue that being eloquent might not benefit a candidate becuase people are interested in everyday speeches.



# Further Reading

https://www.favstats.eu/post/demdebates/


