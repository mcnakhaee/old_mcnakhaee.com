<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python | Muhammad Chenariyan Nakhaee</title>
    <link>/tags/python/</link>
      <atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <description>Python</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 08 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar.jpg</url>
      <title>Python</title>
      <link>/tags/python/</link>
    </image>
    
    <item>
      <title>Analyzing the 2020 Democratic Presidential Debates - Part 2</title>
      <link>/post/2020-03-08-analayzing-the-2020-democratic-presidential-debates-part-2/</link>
      <pubDate>Sun, 08 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-03-08-analayzing-the-2020-democratic-presidential-debates-part-2/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;blockquote&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is not be possible for many of us to watch every 2020 Democratic Primary debate. Nevertheless, it is important for us to know what happened during a debate. In my case I usually read about debates in online newspapers or watch a highlight of a debate on Youtube. However, online newspapers and Youtube channels provide a short summary of a debate or just broadcast a portion of it that includes a heated exchange of opinions and attract attentions. This way many important issues raised by candidates are lik&lt;strong&gt;ely being ignored and forgotten in the&lt;/strong&gt; aftermath of a debate. What if we can summarize the content of a debate in such a way that My goal from this analysis is to use data science techniques to explore the content of debates and give you a comprehensive summary of topics that were discussed by each candidate. This article describes how to I used natural language processing techniques to summarize the content of debates.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://mcnakhaee.com/post/2020-02-23-the-most-eloeuent-democratic-candidate/&#34;&gt;In my last blog post&lt;/a&gt;, I explained that I had the three following goals in mind I study the 2020 Democratic Debates from:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Determining the most eloquent presidential candidate.&lt;/li&gt;
&lt;li&gt;Sentiment analysis of the transcripts to find out who used positive or most negative words on the stage.&lt;/li&gt;
&lt;li&gt;Network analysis of the transcripts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also, I only discussed how I approached the first two aspects of my experiment. Now it is time to explore the third and last aspect by applying network analysis to the transcript.&lt;/p&gt;
&lt;p&gt;My aim from using network analysis is to determine potential allies and enemies on the debate stage. For example, &lt;a href=&#34;https://www.theguardian.com/us-news/2020/mar/04/mike-bloomberg-out-60-second-attack-elizabeth-warren-destroyed-campaign&#34;&gt;Elizabeth Warren mentioned Mike Bloomberg several times and attacked him harshly in the 9th debate&lt;/a&gt;. During the same debate, &lt;a href=&#34;https://www.independent.co.uk/news/world/americas/us-election/amy-klobuchar-pete-buttigieg-handshake-democratic-debate-video-a9348621.html&#34;&gt;Amy Klobuchar and Pete Buttigieg clashed bitterly with each other&lt;/a&gt;. But these two examples are just two instances of many other heated exchanges between the candidates.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To make things more clear, I transformed my goal into two questions that I would like to answer:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;How many times did a candidate address (mention) other candidates during a debate?&lt;/li&gt;
&lt;li&gt;How did he/she do it (in a friendly or unfriendly manner)?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;A simple approach to answer these questions is to store the names of all candidates in a variable (for example a vector in R or a list in Python), iterate through the transcript, measure the its sentiment , and count and store the number of times that a candidate’s name was brought up by another candidate.&lt;/p&gt;
&lt;p&gt;However, adopting this solution is a little bit challenging and requires a lot of manual data pre-processing efforts. For each democratic candidate, I had to compile a comprehensive list of possible ways that may be used to address that candidate. As you can guess this solution seems to be a very time-consuming task. For example, Bernie Sanders might have been mentioned by other candidates in many different ways including Bernie, Bernie Sanders or Senator Sanders.&lt;/p&gt;
&lt;p&gt;I realized that I can use a different but smarter approach to extract the names of candidate from the transcript and still achieve my goal. Also, using this approach not only I can find candidates’ names form the transcript, but also I can find the names of other politicians, individuals and even organization and I can extend my analysis to them.&lt;/p&gt;
&lt;p&gt;I used a very powerful technique from Natural Language Processing (NLP) literature called Names Entity Recognition (NER) to extract the name of candidates.&lt;/p&gt;
&lt;p&gt;I made use of both python and R in my analysis. My workflow includes the following steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I download the transcript of debates using this package (R).&lt;/li&gt;
&lt;li&gt;I use tidytext to tokenize the transcript by splitting into multiple sentences and also for sentiment analysis (R).&lt;/li&gt;
&lt;li&gt;I extract several pre-defined categories Named Entities from each sentence using Spacy.(Python)&lt;/li&gt;
&lt;li&gt;I compute the sentiment of each sentence using TextBlob library (Python).&lt;/li&gt;
&lt;li&gt;I transferred the results to R for visualization. There, I visualize the network of mentions and entities using ggraph and ggplot library.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I used a very powerful Natural Langugae Processing technique called Names Entity Recognition (NER) to extract the name of candidates.&lt;/p&gt;
&lt;p&gt;I took The following steps:
1. I access the transcript of debates using this package.
2. I use tidytext to split the transcript into multiple sentences and also for sentiment analysis.
3. I extract several types of Named Entities from each sentence using Spacy,
4. I compute the sentiment of each sentence using TextBlob library in Python.
5. I transferred the results to R for visualization. There, I visualize the network of mentions and entities using ggraph and ggplot library.
I could have implemented all the steps above in R. Spacyr is a . However, using python was a challenge and a personal decision for me.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(demdebates2020)
library(tidytext)
library(tidygraph)
library(tidyverse)
library(ggraph)
library(gghighlight)
library(ggthemes)
library(kableExtra)
library(reticulate)
library(magrittr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(debates) &lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
speaker
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
background
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
speech
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
gender
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
debate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
day
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
order
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Savannah Guthrie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
All right. So with that business out of the way, we want to get to it. And we’ll start this evening with Senator Elizabeth Warren.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Savannah Guthrie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Senator, good evening to you.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elizabeth Warren
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Thank you. Good to be here.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Savannah Guthrie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
You have many plans - free college, free child care, government health care, cancellation of student debt, new taxes, new regulations, the breakup of major corporations. But this comes at a time when 71 percent of Americans say the economy is doing well, including 60 percent of Democrats. What do you say to those who worry this kind of significant change could be risky to the economy?
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elizabeth Warren
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
So I think of it this way. Who is this economy really working for? It’s doing great for a thinner and thinner slice at the top. It’s doing great for giant drug companies. It’s just not doing great for people who are trying to get a prescription filled.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Elizabeth Warren
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
It’s doing great for people who want to invest in private prisons, just not for the African Americans and Latinx whose families are torn apart, whose lives are destroyed, and whose communities are ruined.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;tokenization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2. Tokenization&lt;/h3&gt;
&lt;p&gt;As I mentioned before, I use tidytext to tokenize the transcript dataset based on sentences.For sentence tokenization, you need to set &lt;code&gt;token = &#39;sentences&#39;&lt;/code&gt; in &lt;code&gt;unnest_tokens()&lt;/code&gt; function. I think sentence tokenization is a reasonable choice because candidates might change the subject or the tone of their speech in each sentence.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;debates &amp;lt;- debates %&amp;gt;%
 unnest_tokens(sentence, speech, token = &amp;#39;sentences&amp;#39;,to_lower = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(debates) &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(debates) %&amp;gt;%
 kable() %&amp;gt;%
 kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
speaker
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
background
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
gender
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
debate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
day
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
order
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
sentence
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(APPLAUSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
222
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(APPLAUSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
283
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(APPLAUSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
285
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(APPLAUSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
328
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(APPLAUSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
576
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Abby Phillip
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(COMMERCIAL BREAK)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moderator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
284
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;named-entity-recognition-using-spacy&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3. Named Entity Recognition using Spacy&lt;/h3&gt;
&lt;p&gt;We need to install and import some python libraries.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
import spacy
from textblob import TextBlob&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In RStudio and with the help of reticulate library, We can easily load the debate dataset from our R environment to our Python environment.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;debates = r.debates&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are rows for both the candidates and the moderators who posed the questions to candidates in the transcript dataset. However, I am particularly interested in what the candidates said, so I only selected rows corresponding to the candidates.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;candidates = debates[(debates[&amp;#39;type&amp;#39;] == &amp;#39;Candidate&amp;#39;) &amp;amp; (pd.notnull(debates[&amp;#39;sentence&amp;#39;])) ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are almost ready for extracting the named entities. But to use Spacy’s NLP features such as NER, we first need to download and load a pre-trained English language model. There are &lt;a href=&#34;https://spacy.io/usage/models&#34;&gt;several English language models&lt;/a&gt; with different sizes available in Spacy. I used the largest language model available.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;nlp = spacy.load(&amp;#39;en_core_web_lg&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spacy’s NER model is trained on the &lt;a href=&#34;https://catalog.ldc.upenn.edu/LDC2013T19&#34;&gt;OntoNotes 5&lt;/a&gt; corpus and it can detect several types of named entities including:
Spacy’s NER model is trained on the &lt;a href=&#34;https://catalog.ldc.upenn.edu/LDC2013T19&#34;&gt;OntoNotes 5&lt;/a&gt; corpus and it can detect several types of named entities including:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;TYPE&lt;/th&gt;
&lt;th&gt;DESCRIPTION&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;PERSON&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;People, including fictional.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;NORP&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Nationalities or religious or political groups.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;FAC&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Buildings, airports, highways, bridges, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;ORG&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Companies, agencies, institutions, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;GPE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Countries, cities, states.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;LOC&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Non-GPE locations, mountain ranges, bodies of water.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;PRODUCT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Objects, vehicles, foods, etc. (Not services.)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;EVENT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Named hurricanes, battles, wars, sports events, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;WORK_OF_ART&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Titles of books, songs, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;LAW&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Named documents made into laws.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;LANGUAGE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Any named language.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;DATE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Absolute or relative dates or periods.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;TIME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Times smaller than a day.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;PERCENT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Percentage, including ”%“.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;MONEY&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Monetary values, including unit.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;QUANTITY&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Measurements, as of weight or distance.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;ORDINAL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;“first”, “second”, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;CARDINAL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Numerals that do not fall under another type.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, there are many types of named entities but I limited my analysis to a handful of them including &lt;code&gt;PERSON&lt;/code&gt;, &lt;code&gt;ORG&lt;/code&gt;, &lt;code&gt;GPE&lt;/code&gt;, &lt;code&gt;NORP&lt;/code&gt;, &lt;code&gt;LAW&lt;/code&gt; and &lt;code&gt;LOC&lt;/code&gt;. When we use &lt;code&gt;nlp&lt;/code&gt;, Spacy tokenizes the documents and then for each token, its named entity clas is determined. The named enitiy labels are stored in &lt;code&gt;label_&lt;/code&gt; attribute. We&lt;/p&gt;
&lt;p&gt;A very useful place to learn more how spacy works the spacy’s online course by one of its founders and developers.&lt;/p&gt;
&lt;p&gt;I defined a python function that for each type of named entities explores the input transcript and extracts all named entities from that piece of text. Later, I store each extracted type of entities as a separate column in the original dataset.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def extract_entities_delim(text,type_ent = &amp;#39;PERSON&amp;#39;):
  ent_text = &amp;#39;&amp;#39;
  doc = nlp(text)
  for e in doc.ents:
    if e.label_ == type_ent:
      ent_text = e.text+ &amp;#39;;&amp;#39; + ent_text 
  return ent_text&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;candidates[&amp;#39;PERSON&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x))
candidates[&amp;#39;ORG&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x,&amp;#39;ORG&amp;#39;))
candidates[&amp;#39;GPE&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x,&amp;#39;GPE&amp;#39;))
candidates[&amp;#39;NORP&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x,&amp;#39;NORP&amp;#39;))
candidates[&amp;#39;LAW&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x,&amp;#39;LAW&amp;#39;))
candidates[&amp;#39;LOC&amp;#39;] = candidates[&amp;#39;sentence&amp;#39;].apply(lambda x:extract_entities_delim(x,&amp;#39;LOC&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sentiment-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;4. Sentiment Analysis&lt;/h3&gt;
&lt;p&gt;Next, I use TextBlob to compute the sentiment of each sentence and store store its polarity score in a separate column called &lt;code&gt;polarity_sentiment&lt;/code&gt;. TextBlob returns a sentiment value between -1 and 1. If the value is larger than 0, it means that the sentence has a positive sentiment. On the other hand, if the returned value is smaller than 0, it indicates that the sentiment of the sentence is negative.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def polarity_sentiment(text):
  blob = TextBlob(text)
  return blob.sentiment.polarity
  
candidates[&amp;#39;polarity_sentiment&amp;#39;] = candidates.sentence.apply(lambda x:polarity_sentiment(x))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;network-visualization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;6.Network Visualization&lt;/h2&gt;
&lt;p&gt;A network (graph) can nicely represent how individuals and entities were mentioned by candidates in their remarks. We have two types of nodes in this network:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The first set of nodes represent candidates on the debate stage (&lt;strong&gt;from nodes)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The second set of nodes represent named entities (including the name of candidates themselves) that the candidates referred to in their speeches (&lt;strong&gt;to&lt;/strong&gt; &lt;strong&gt;nodes&lt;/strong&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If a candidate speaks of a named entity in his/her speech, we connect the candidate node and the named entity node via an edge in our network. Also, It is fair to assume that the candidate-entity network should be a weighted network because candidates tend to place a varying level of importance on different issues and topics.&lt;/p&gt;
&lt;p&gt;We have two options for specifying edges in the network:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We can use the number of times that a candidate mentioned a named entity in his/her speech. This shows how much a named entity was important to that candidate.&lt;/li&gt;
&lt;li&gt;We can group by candidates and named entities and compute their average sentiment score. By doing so, we can measure how each candidate described these named entities.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, it is time to go back to R and visualize the network of candidates and named entities using the &lt;a href=&#34;https://github.com/thomasp85/ggraph&#34;&gt;&lt;code&gt;ggraph&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;tidygraph&lt;/code&gt; libraries. For each class of named entities, I use &lt;code&gt;as_tbl_graph()&lt;/code&gt; function and create a unique graph table dataset , and visualize the network separately.&lt;/p&gt;
&lt;p&gt;Again, I should point out to the fact that in the beginning of the primary there were many democratic candidates in the race and also on the debate stage. If I visualize every individual that each candidate had ever mentioned, the results will become unreadable. So, just like my last blog post, I selected a few democratic candidates to show my analysis. Additionally, I only use data from the last three debates but extending my analysis to other debates is extremely easy.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interesting_people &amp;lt;-
 c(
  &amp;quot;Bernie Sanders&amp;quot; ,
  &amp;quot;Elizabeth Warren&amp;quot; ,
  &amp;quot;Mike Bloomberg&amp;quot;  ,
  &amp;quot;Pete Buttigieg&amp;quot; ,
  &amp;quot;Amy Klobuchar&amp;quot; ,
  &amp;quot;Joe Biden&amp;quot;,
  &amp;#39;Donald Trump&amp;#39;,
  &amp;#39;Barack Obama&amp;#39;
 )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s move the sentiment-entity dataset that I created in Python to R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;candidates &amp;lt;- py$candidates&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(candidates) &lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
speaker
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
background
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
gender
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
debate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
day
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
order
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
sentence
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
PERSON
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
ORG
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
GPE
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
NORP
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
LAW
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
LOC
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
polarity_sentiment
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
370
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Well, first, the economy.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.250
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
371
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
We know that not everyone is sharing in this prosperity.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
372
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
And Donald Trump just sits in the White House and gloats about what’s going on, when you have so many people that are having trouble affording college and having trouble affording their premiums.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Donald Trump;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.025
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
373
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
So I do get concerned about paying for college for rich kids.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.375
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
374
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
I do.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
375
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Amy Klobuchar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Candidate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
But I think my plan is a good one.
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.700
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;the-candidateperson-network&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;5.1 The Candidate/Person Network&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;persons_graph_table &amp;lt;- candidates %&amp;gt;%
 separate_rows(PERSON, sep = &amp;#39;;&amp;#39;) %&amp;gt;%
 filter(speaker %in% interesting_people,PERSON != &amp;#39;&amp;#39;, debate %in% c(8, 9, 10)) %&amp;gt;%
 mutate(from = speaker, to = PERSON) %&amp;gt;%
 group_by(from, to) %&amp;gt;%
 summarize(n_mentions = n(),
      mean_sent = mean(polarity_sentiment),
      sent =case_when(mean_sent &amp;lt; -0.01 ~ &amp;#39;Negative&amp;#39;,
               mean_sent &amp;gt; 0.01 ~ &amp;#39;Positive&amp;#39;,
              TRUE ~ &amp;#39;Neutral&amp;#39; )
               ) %&amp;gt;%
 ungroup() %&amp;gt;%
 as_tbl_graph() %&amp;gt;%
 mutate(interesting_people = if_else(name %in% interesting_people, name, &amp;#39;Others&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;custom_palette &amp;lt;-
 c(
  &amp;#39;Mike Bloomberg&amp;#39; = &amp;#39;#F6E560&amp;#39;,
  &amp;#39;Amy Klobuchar&amp;#39; = &amp;#39;#8ADDAF&amp;#39; ,
  &amp;#39;Joe Biden&amp;#39; = &amp;#39;#C42199&amp;#39;,
  &amp;#39;Pete Buttigieg&amp;#39; = &amp;#39;#DA8B46&amp;#39;,
  &amp;#39;Elizabeth Warren&amp;#39; = &amp;#39;#845CCD&amp;#39;,
  &amp;#39;Bernie Sanders&amp;#39; = &amp;#39;#409EB1&amp;#39;,
  &amp;#39;Donald Trump&amp;#39; = &amp;#39;#1d1b21&amp;#39;,
  &amp;#39;Barack Obama&amp;#39; = &amp;#39;#AAB3AD&amp;#39;,
  &amp;#39;Others&amp;#39; =&amp;#39;#50514f&amp;#39;
 )
edge_cols &amp;lt;- c(&amp;#39;#e63946&amp;#39;,&amp;#39;#f1faee&amp;#39;,&amp;#39;#457B9D&amp;#39;)
ggraph(persons_graph_table, layout = &amp;#39;kk&amp;#39;) + 
  geom_edge_link(aes(edge_width = n_mentions,colour = sent )) +
  geom_node_point(aes(color = interesting_people ),size = 5) + 
  geom_node_label(aes(label = name,color = interesting_people),repel = TRUE,size= 8) + 
 scale_color_manual(values = custom_palette) +

  theme_graph(foreground = &amp;#39;steelblue&amp;#39;, fg_text_colour = &amp;#39;white&amp;#39;) +
labs(title = &amp;#39;Who Mentioned Whom in the 2020 Democratic Debates?&amp;#39;) +
scale_edge_colour_manual(values = edge_cols) +
 theme_graph(
       base_family = &amp;#39;Montserrat&amp;#39;,) +
 theme(
   plot.title = element_text(
   family = &amp;#39;Montserrat&amp;#39;,
   face = &amp;quot;bold&amp;quot;,
   size = 50,
   margin = ggplot2::margin(0, 0, 20, 0),
   hjust = 0.5
  ),
  legend.position = &amp;#39;none&amp;#39;
  
 )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-08-analayzing-the-2020-democratic-presidential-debates-part-2/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you look at the graph carefully, you will notice that there are two issues with this network. First of all, there are several nodes in the network that belong to the same individual. For example, Bernie Sanders tends to address other candidates by their first names but other (younger) candidates usually use the last name to address each other.
Secondly, some nodes do not represent a person. The transcript dataset is full of errors and many names are misspelled. Also, although Spacy is a very powerful library for NER, sometimes it gives us wrong results and its detected named entities are not always correct t. For this reason, we also need to perform a post-precessing step in which we remove some incorrectly spelled words or replaced them with their correct forms. I found two ways to deal with issue:1. we can manually find undesirable names and replace them with what we want 2. or we can use a match naming algorithm to match the partial names of a person with its full name.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;matching-names&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;5.2 Matching names&lt;/h4&gt;
&lt;p&gt;There is a python library called &lt;code&gt;fuzzywuzzy&lt;/code&gt; that can help us match two strings based on different criteria. Here, I move back the candidate dataset to our python environment. But before that, I transform the oeiginal dataset into a longer dataset where each row belongs to a pair of candidate-person (from-to) instance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;candidates_long &amp;lt;- candidates %&amp;gt;%
 filter(PERSON != &amp;#39;&amp;#39;) %&amp;gt;%
 separate_rows(PERSON, sep = &amp;#39;;&amp;#39;) 
head(candidates_long)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-tibble-6-x-16&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A tibble: 6 x 16&lt;/h1&gt;
&lt;p&gt;X1 speaker background type gender debate day order sentence PERSON ORG&lt;br /&gt;
&lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
1 372 Amy Kl~ NA Cand~ female 1 1 11 And Don~ “Dona~ &lt;NA&gt;
2 372 Amy Kl~ NA Cand~ female 1 1 11 And Don~”&#34; &lt;NA&gt;
3 384 Amy Kl~ NA Cand~ female 1 1 99 It’s so~ “Bara~ &lt;NA&gt;
4 384 Amy Kl~ NA Cand~ female 1 1 99 It’s so~”&#34; &lt;NA&gt;
5 422 Amy Kl~ NA Cand~ female 1 1 329 But the~ “Dona~ &lt;NA&gt;
6 422 Amy Kl~ NA Cand~ female 1 1 329 But the~”&#34; &lt;NA&gt;
# … with 5 more variables: GPE &lt;chr&gt;, NORP &lt;chr&gt;, LAW &lt;chr&gt;, LOC &lt;chr&gt;,
# polarity_sentiment &lt;dbl&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;candidates_long = r.candidates_long&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;candidate_lists = pd.unique(candidates_long.speaker)
print(candidate_lists)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [&amp;#39;Amy Klobuchar&amp;#39; &amp;#39;Andrew Yang&amp;#39; &amp;#39;Bernie Sanders&amp;#39; &amp;quot;Beto O&amp;#39;Rourke&amp;quot;
##  &amp;#39;Bill de Blasio&amp;#39; &amp;#39;Cory Booker&amp;#39; &amp;#39;Elizabeth Warren&amp;#39; &amp;#39;Eric Swalwell&amp;#39;
##  &amp;#39;Jay Inslee&amp;#39; &amp;#39;Joe Biden&amp;#39; &amp;#39;John Delaney&amp;#39; &amp;#39;John Hickenlooper&amp;#39;
##  &amp;#39;Julian Castro&amp;#39; &amp;#39;Kamala Harris&amp;#39; &amp;#39;Kirsten Gillibrand&amp;#39;
##  &amp;#39;Marianne Williamson&amp;#39; &amp;#39;Michael Bennet&amp;#39; &amp;#39;Mike Bloomberg&amp;#39; &amp;#39;Pete Buttigieg&amp;#39;
##  &amp;#39;Steve Bullock&amp;#39; &amp;#39;Tim Ryan&amp;#39; &amp;#39;Tom Steyer&amp;#39; &amp;#39;Tulsi Gabbard&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I &lt;code&gt;process.extractOne&lt;/code&gt; function to select the first matched name that has at&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from fuzzywuzzy import fuzz 
from fuzzywuzzy import process &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def match_names(name):
  try:
    return process.extractOne(name, candidate_lists,score_cutoff = 80)[0] 
  except:
    return None

candidates_long[&amp;#39;dem_candidate_full_name&amp;#39;] = candidates_long.PERSON.apply(lambda x: match_names(x) )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;candidates_long &amp;lt;- read_csv(&amp;#39;candidates_long_sentiment_entities.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   speaker = col_character(),
##   background = col_logical(),
##   type = col_character(),
##   gender = col_character(),
##   debate = col_double(),
##   day = col_double(),
##   order = col_double(),
##   sentence = col_character(),
##   PERSON = col_character(),
##   ORG = col_character(),
##   GPE = col_character(),
##   NORP = col_character(),
##   LAW = col_character(),
##   LOC = col_character(),
##   polarity_sentiment = col_double(),
##   dem_candidate_full_name = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;candidates_long &amp;lt;- py$candidates_long
glimpse(candidates_long)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 1,732
## Variables: 16
## $ speaker                 &amp;lt;chr&amp;gt; &amp;quot;Amy Klobuchar&amp;quot;, &amp;quot;Amy Klobuchar&amp;quot;, &amp;quot;Amy Klob...
## $ background              &amp;lt;dbl&amp;gt; NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN...
## $ type                    &amp;lt;chr&amp;gt; &amp;quot;Candidate&amp;quot;, &amp;quot;Candidate&amp;quot;, &amp;quot;Candidate&amp;quot;, &amp;quot;Can...
## $ gender                  &amp;lt;chr&amp;gt; &amp;quot;female&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;fe...
## $ debate                  &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2...
## $ day                     &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
## $ order                   &amp;lt;dbl&amp;gt; 11, 99, 329, 426, 427, 563, 567, 674, 725, ...
## $ sentence                &amp;lt;chr&amp;gt; &amp;quot;And Donald Trump just sits in the White Ho...
## $ PERSON                  &amp;lt;chr&amp;gt; &amp;quot;Donald Trump&amp;quot;, &amp;quot;Barack Obama&amp;quot;, &amp;quot;Donald Tru...
## $ ORG                     &amp;lt;list&amp;gt; [NaN, NaN, NaN, NaN, &amp;quot;Senate;&amp;quot;, NaN, NaN, ...
## $ GPE                     &amp;lt;list&amp;gt; [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N...
## $ NORP                    &amp;lt;list&amp;gt; [NaN, NaN, NaN, NaN, NaN, &amp;quot;Democrat;&amp;quot;, NaN...
## $ LAW                     &amp;lt;list&amp;gt; [NaN, &amp;quot;the Affordable Care Act;&amp;quot;, NaN, NaN...
## $ LOC                     &amp;lt;list&amp;gt; [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, N...
## $ polarity_sentiment      &amp;lt;dbl&amp;gt; 0.0250000, 0.0000000, 0.5000000, 0.8000000,...
## $ dem_candidate_full_name &amp;lt;list&amp;gt; [NaN, NaN, NaN, NaN, NaN, NaN, &amp;quot;Cory Booke...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;non_person &amp;lt;- c(&amp;#39;y adema&amp;#39; ,&amp;#39;Appalachia&amp;#39; , &amp;#39;AUMF&amp;#39; ,&amp;#39;bias&amp;#39;,&amp;#39;nondisclosur&amp;#39; , &amp;#39;Mathew 25&amp;#39;,&amp;#39;Idlib&amp;#39;,&amp;#39;ye&amp;#39;,&amp;#39;Everytown&amp;#39;,&amp;#39;Kurd&amp;#39;,&amp;#39;Roe V.&amp;#39;,&amp;#39;Wade&amp;#39;)

persons_graph_table &amp;lt;- candidates_long %&amp;gt;%
 filter(speaker %in% interesting_people, debate %in% c(7,8, 9, 10),!PERSON %in% non_person) %&amp;gt;%
 dplyr::rowwise() %&amp;gt;% 
 mutate(dem_candidate_full_name = as.character(dem_candidate_full_name)) %&amp;gt;% 
 mutate(PERSON = if_else(dem_candidate_full_name!=&amp;#39;NaN&amp;#39;,dem_candidate_full_name,PERSON)) %&amp;gt;% 
 mutate(from = speaker, to = PERSON) %&amp;gt;%
 mutate(  
  to = case_when(
 to %in% c(&amp;#39;Donald&amp;#39;,&amp;#39;Donald Trump&amp;#39;, &amp;#39;Trump&amp;#39;, &amp;#39;President Trump&amp;#39;,&amp;quot;Donald Trump&amp;#39;s&amp;quot;) ~ &amp;#39;Donald Trump&amp;#39;,
 str_detect(to,&amp;#39;Vind&amp;#39;)~&amp;#39;Vindman&amp;#39;,
 str_detect(to,&amp;#39;Assad&amp;#39;)~&amp;#39;Assad&amp;#39;, 
 str_detect(to,&amp;#39;Trudeau&amp;#39;) ~ &amp;#39;Justin Trudeau&amp;#39;, 
 str_detect(to,&amp;#39;Bannon&amp;#39;) ~ &amp;#39;Steve Bannon&amp;#39;, 
 str_detect(to,&amp;#39;Netanyahu&amp;#39;) ~ &amp;#39;Netanyahu&amp;#39;, 
 str_detect(to,&amp;#39;Martin Luther&amp;#39;) ~ &amp;#39;Martin Luther King&amp;#39;, 
 str_detect(to,&amp;#39;Hillar&amp;#39;) ~ &amp;#39;Hillary Clinton&amp;#39;, 
 str_detect(to,&amp;#39;Obama&amp;#39;) ~ &amp;#39;Barack Obama&amp;#39;,
 str_detect(to,&amp;#39;Barack&amp;#39;) ~ &amp;#39;Barack Obama&amp;#39;,
 str_detect(to,&amp;#39;Mandela&amp;#39;) ~ &amp;#39;Mandela&amp;#39;, 
 str_detect(to,&amp;#39;Xi&amp;#39;) ~ &amp;#39;Xi Jinping&amp;#39;,
 str_detect(to,&amp;#39;Putin&amp;#39;) ~ &amp;#39;Putin&amp;#39;,
 str_detect(to,&amp;#39;Mitch&amp;#39;) ~ &amp;#39;Mitch Mcconnell&amp;#39;,
 str_detect(to,&amp;#39;Lindsey&amp;#39;) ~ &amp;#39;Lindsey Graham&amp;#39;,
 str_detect(to,&amp;#39;Romney&amp;#39;) ~ &amp;#39;Mitt Romney&amp;#39;,
 str_detect(to,&amp;#39;George&amp;#39;) ~ &amp;#39;George Bush&amp;#39;,
 str_detect(to,&amp;#39;Bush&amp;#39;) ~ &amp;#39;George Bush&amp;#39;,
 str_detect(to,&amp;#39;Turner&amp;#39;) ~ &amp;#39;Nina Turner&amp;#39;,
 str_detect(to,&amp;#39;Clyburn&amp;#39;) ~ &amp;#39;Jim Clyburn&amp;#39;, 
 str_detect(to,&amp;#39;Shaheen&amp;#39;) ~ &amp;#39;Jeanne Shaheen&amp;#39;,
 TRUE ~ to
)) %&amp;gt;% 
 group_by(from, to) %&amp;gt;%
 summarize(n_mentions = n()) %&amp;gt;%
 ungroup() %&amp;gt;%
 as_tbl_graph() %&amp;gt;%
 mutate(interesting_people = if_else(name %in% interesting_people, name, &amp;#39;Others&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_graph &amp;lt;- function(graph_table) {
  ggraph(graph_table, layout = &amp;#39;nicely&amp;#39;) +
    geom_edge_link(aes(
      edge_width = n_mentions,
      colour = n_mentions,
      fill = n_mentions
    )) +
    #geom_node_point(aes(color = interesting_people), size = 5) +
    geom_node_label(aes(label = name, color = interesting_people),
                    repel = TRUE,
                    size = 8) +
    scale_fill_manual(values = custom_palette) +
    
    theme_graph(foreground = &amp;#39;steelblue&amp;#39;, fg_text_colour = &amp;#39;white&amp;#39;) +
    labs(title = &amp;#39;Who Mentioned Whom?&amp;#39; ,
         subtitle = &amp;#39; in the 2020 Democratic Debates&amp;#39;,
         caption = &amp;#39;Visualization: @m_cnakhaee\n\n Source: https://github.com/favstats/demdebates2020&amp;#39;) +
    #scale_edge_colour_manual(values = edge_cols) +
    scale_edge_colour_gradient2() +
    scale_edge_fill_gradient2() +
    theme_graph(base_family = &amp;#39;Montserrat&amp;#39;,) +
    theme(
      plot.title = element_text(
        family = &amp;#39;Montserrat&amp;#39;,
        face = &amp;quot;bold&amp;quot;,
        size = 50,
        margin = ggplot2::margin(0, 0, 20, 0),
        hjust = 0.5
      ),
      plot.subtitle = element_text(
        family = &amp;#39;Montserrat&amp;#39;,
        face = &amp;quot;bold&amp;quot;,
        size = 20,
        margin = ggplot2::margin(0, 0, 20, 0),
        hjust = 0.5
      ),
      legend.position = &amp;#39;none&amp;#39;
    )
}


plot_graph(persons_graph_table)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-08-analayzing-the-2020-democratic-presidential-debates-part-2/index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;candidates_long %&amp;gt;%
  filter(!is.na(dem_candidate_full_name)) %&amp;gt;% 
  select(PERSON,dem_candidate_full_name,sentence) %&amp;gt;% 
  View()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;candidates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5.3 Candidates&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_candidates &amp;lt;- candidates_long %&amp;gt;%
 distinct(speaker)%&amp;gt;%
 pull()

candidates_graph_table &amp;lt;- candidates_long %&amp;gt;%
 filter(!is.na(dem_candidate_full_name) ) %&amp;gt;%
 rowwise() %&amp;gt;%
  mutate(debate= as.factor(debate)) %&amp;gt;% 
  mutate(dem_candidate_full_name = as.character(dem_candidate_full_name)) %&amp;gt;% 
 mutate(from = speaker, to = dem_candidate_full_name) %&amp;gt;%
   group_by(from, to,debate) %&amp;gt;%
 summarize(n_mentions = n()
               ) %&amp;gt;%
 ungroup() %&amp;gt;%
 as_tbl_graph(directed = TRUE) %&amp;gt;%
 mutate(interesting_people = if_else(name %in% interesting_people, name, &amp;#39;Others&amp;#39;)) %&amp;gt;% 
 activate(nodes) %&amp;gt;% 
 mutate(
  bet_cent = centrality_betweenness(),
  deg_cent = centrality_degree(),
  
 )
candidates_graph_table&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tbl_graph: 23 nodes and 291 edges
## #
## # A directed multigraph with 1 component
## #
## # Node Data: 23 x 4 (active)
##   name           interesting_people bet_cent deg_cent
##   &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                 &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 Amy Klobuchar  Amy Klobuchar         13.7        30
## 2 Andrew Yang    Others                 4.58       14
## 3 Bernie Sanders Bernie Sanders       116.         50
## 4 Beto O&amp;#39;Rourke  Others                31.3        10
## 5 Bill de Blasio Others                 1.11        4
## 6 Cory Booker    Others                16.7        13
## # ... with 17 more rows
## #
## # Edge Data: 291 x 4
##    from    to debate n_mentions
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt;
## 1     1     1 4               1
## 2     1     2 4               2
## 3     1     2 8               1
## # ... with 288 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# preparing the circular layout for the network
full_layout &amp;lt;- create_layout(graph = candidates_graph_table, layout = &amp;quot;linear&amp;quot;, circular = T)

xmin &amp;lt;- min(full_layout$x)
xmax &amp;lt;- max(full_layout$x)
ymin &amp;lt;- min(full_layout$y)
ymax &amp;lt;- max(full_layout$y)

ggraph(
  full_layout,
  layout = &amp;#39;manual&amp;#39;,
  x = x,
  y = y,
  circular = TRUE
) +
  geom_edge_arc(
    aes(
      edge_width = n_mentions,
      colour = n_mentions,
    ),
    
  alpha =0.5
  ) +
  geom_node_point(aes(color = interesting_people, size = deg_cent)) +
  geom_node_text(
    aes(
      label = name,
      color = interesting_people,
      x = x * 1.15,
      y = y * 1.15,
      angle = ifelse(
        atan(-(x / y)) * (180 / pi) &amp;lt; 0,
        90 + atan(-(x / y)) * (180 / pi),
        270 + atan(-x / y) * (180 / pi)
      )),
      size = 4
    ) +
      scale_fill_manual(values = custom_palette) +
      
      theme_graph(foreground = &amp;#39;steelblue&amp;#39;, fg_text_colour = &amp;#39;white&amp;#39;) +
      labs(title = &amp;#39;How candidates interacted 2020 Democratic Debates&amp;#39;) +
      #scale_edge_colour_manual(values = edge_cols) +
      scale_edge_colour_gradient2() +
      #scale_edge_fill_gradient2() +
      #facet_edges( ~ debate, ncol = 2) +
    expand_limits(x = c(xmin - 0.2, xmax + 0.2),
                y = c(ymin - 0.2, ymax + 0.2)) +
      theme_graph(base_family = &amp;#39;Montserrat&amp;#39;,) +
      theme(
        plot.title = element_text(
          family = &amp;#39;Montserrat&amp;#39;,
          face = &amp;quot;bold&amp;quot;,
          size = 50,
          margin = ggplot2::margin(0, 0, 20, 0),
          hjust = 0.5
        ),
        legend.position = &amp;#39;none&amp;#39;
        
      )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-08-analayzing-the-2020-democratic-presidential-debates-part-2/index_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colors &amp;lt;- c(&amp;#39;#C42199&amp;#39;, &amp;#39;#409EB1&amp;#39;,&amp;#39;#845CCD&amp;#39;,&amp;#39;#DA8B46&amp;#39;, &amp;#39;#F6E560&amp;#39;, &amp;#39;#8ADDAF&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;http://www.favstats.eu/post/demdebates/&#34; class=&#34;uri&#34;&gt;http://www.favstats.eu/post/demdebates/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidymodel for Scikit-Learn Users and Vise Versa</title>
      <link>/post/2020-02-14-tidymodel-for-scikit-learn-users-and-vise-versa/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-02-14-tidymodel-for-scikit-learn-users-and-vise-versa/</guid>
      <description>


&lt;p&gt;Advantages
There are many ways to do one thing
The output is a table which you can use as an input to everything that works with a table&lt;/p&gt;
&lt;p&gt;Disadvantages&lt;/p&gt;
&lt;p&gt;##Classification Models&lt;/p&gt;
&lt;div id=&#34;regression-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regression Models&lt;/h2&gt;
&lt;div id=&#34;making-prediction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Making Prediction&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;model-selection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model selection&lt;/h3&gt;
&lt;p&gt;reasonable defaults for tidymodel&lt;/p&gt;
&lt;p&gt;tidymodel by default tuning paramters are set for us. We can also specify them ourselves.&lt;/p&gt;
&lt;p&gt;you can even tune the preprocessing steps in Tidymodel.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;pipelines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pipelines&lt;/h2&gt;
&lt;p&gt;pipelines are handy:
they make your code much shorter
data leakage&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pre-Processing&lt;/h2&gt;
&lt;p&gt;inverse transform&lt;/p&gt;
&lt;div id=&#34;section&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;My preferable way&lt;/p&gt;
&lt;p&gt;Automatic machine learning&lt;/p&gt;
&lt;p&gt;parellal processing&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What Makes a Song Popular? An Explainable Machine Learning Approach</title>
      <link>/post/2020-02-11-what-makes-a-song-popular-an-explainable-machine-learning-approach/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-02-11-what-makes-a-song-popular-an-explainable-machine-learning-approach/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tune)
library(rsample)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: tidyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(yardstick)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## For binary classification, the first factor level is assumed to be the event.
## Set the global option `yardstick.event_first` to `FALSE` to change this.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dials)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: scales&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(workflows)
library(parsnip)
library(infer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#devtools::install_github(&amp;quot;tidymodels/tidymodels&amp;quot;)
#remotes::install_github(&amp;quot;wilkelab/ggtext&amp;quot;,build = &amp;#39;binary&amp;#39;)
library(tidyverse)
library(tidymodels)
library(lubridate)
library(corrr)
library(pins)
library(genius)
library(reticulate)

spotify_songs &amp;lt;- pin(read_csv(&amp;#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv&amp;#39;))
head(spotify_songs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 23
##   track_id track_name track_artist track_popularity track_album_id
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         
## 1 6f807x0~ I Don&amp;#39;t C~ Ed Sheeran                 66 2oCs0DGTsRO98~
## 2 0r7CVbZ~ Memories ~ Maroon 5                   67 63rPSO264uRjW~
## 3 1z1Hg7V~ All the T~ Zara Larsson               70 1HoSmj2eLcsrR~
## 4 75Fpbth~ Call You ~ The Chainsm~               60 1nqYsOef1yKKu~
## 5 1e8PAfc~ Someone Y~ Lewis Capal~               69 7m7vv9wlQ4i0L~
## 6 7fvUMiy~ Beautiful~ Ed Sheeran                 67 2yiy9cd2QktrN~
## # ... with 18 more variables: track_album_name &amp;lt;chr&amp;gt;,
## #   track_album_release_date &amp;lt;chr&amp;gt;, playlist_name &amp;lt;chr&amp;gt;, playlist_id &amp;lt;chr&amp;gt;,
## #   playlist_genre &amp;lt;chr&amp;gt;, playlist_subgenre &amp;lt;chr&amp;gt;, danceability &amp;lt;dbl&amp;gt;,
## #   energy &amp;lt;dbl&amp;gt;, key &amp;lt;dbl&amp;gt;, loudness &amp;lt;dbl&amp;gt;, mode &amp;lt;dbl&amp;gt;, speechiness &amp;lt;dbl&amp;gt;,
## #   acousticness &amp;lt;dbl&amp;gt;, instrumentalness &amp;lt;dbl&amp;gt;, liveness &amp;lt;dbl&amp;gt;, valence &amp;lt;dbl&amp;gt;,
## #   tempo &amp;lt;dbl&amp;gt;, duration_ms &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs &amp;lt;- spotify_songs %&amp;gt;%  
  dplyr::rowwise() %&amp;gt;% 
  mutate(shorter_names = unlist(str_split(track_name,&amp;#39;-&amp;#39;))[1]) &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs &amp;lt;- py$spotify_songs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Have you ever wondered why some songs from an artist become so popular and others are just total failure?
Look at the next plot. Even The Beetles had a few not so popular songs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aptheme)
spotify_songs %&amp;gt;%
  filter(track_artist == &amp;#39;The Beatles&amp;#39;, track_popularity &amp;gt; 10) %&amp;gt;%
  ggplot(aes(x = track_popularity)) +
 geom_histogram() +
  theme_ap() + theme(legend.position = &amp;#39;bottom&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-what-makes-a-song-popular-an-explainable-machine-learning-approach/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So what can be the recipe for popularity? Or why does a song become(un)popular? Is it solely releated to the artists that play a song? Can it be the song’s audio features?&lt;/p&gt;
&lt;p&gt;##Exploratory Data Analysis&lt;/p&gt;
&lt;div id=&#34;machine-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;Another more complex way to look at this problem is to use machine learning algorithms. We can train a machine learning model to accurately predict the popularity of a song. Now if we look inside the patterns that this model learning model has learned, we might be able to find out why a song has become popular or unpopular.
In the second part of this post, I will demonstrate how I designed a machine learning workflow to predict the popularity of songs based on several audio features. Here my goal from using an ML model is not just to predict popularity but rather to figure out which factors contribute to it.&lt;/p&gt;
&lt;p&gt;However, peeking inside an ML algorithm and discovering how it makes prediction is not alwayse straighforward. Only the inner-workings of a few ML algorithms such as decision trees and linear modelsare transparent. These algorithms are very simple and might be powerful enough to model the complexities and the common knowledge is that they are not accurate. Of course you can make a decision tree fairly accurate by increasing its depth but the resulting tree would become exteremly messy and hard to understand.In addition, deeper tree are more likely to overfit.&lt;/p&gt;
&lt;p&gt;There are also more powerful and more accurate algorithms such as random forests, xgboost or deep neural networks but understanding how they make predictions is very challenging (sometimes they are called black-box models). That is translated to a widespread belief amont ML community that there is a trade-off between the accuracy and the interpretability of an ML algorithm. However, a few other researchers reject this claim and believe it is just a popular myth and you can indeed find an interpretable and accurate ML algorithm.&lt;/p&gt;
&lt;p&gt;Anyways, over the past five years a lot of methods have been proposed to some “approximate” how an ML algorithm predicts an outcome. Two popular methods that are widely used to interpret machine learning algorithms are LIME and SHAP.&lt;/p&gt;
&lt;p&gt;We can look inside a machine learning algorithms from two aspects:&lt;/p&gt;
&lt;p&gt;Based on what feature values, an ML algorithm has made prediction about the popularity of “a particular” song. Local explanations
Global explanations such as feature importance scores to understand to the popularity of songs.&lt;/p&gt;
&lt;p&gt;In this part of my post, first I will train a random forest and an XGBoost model to predict song popularity and then I will discover how they make prediction using SHAP, LIME and feature importance scores. Hopefully, these patterns can help us better understand which factors might contribute to a song’s popularity.&lt;/p&gt;
&lt;p&gt;To use a explainable machine learning methods for this purpose, it is important to obtain a reasonable performance on the prediction task. Otherwise, the result would be unreliable and useless.&lt;/p&gt;
&lt;p&gt;I won’t use common pre-processing steps such as normalization because random forest and XGBoost are not sensitive to non-normalized data. Also, some pre-processing steps might make the interpretation of the results less intuitive.&lt;/p&gt;
&lt;p&gt;I have mainly used scikit-learn for training ML models but recently I have become passionately interested in the Tidymodels ecosystem. So, here I have decided to use Tidymodels and its features for model development.
Workflows are similar to &lt;code&gt;pipelines&lt;/code&gt; in scikit-learn.
My designed workflow consists of the following step:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;I create a preprocessing recipe using the &lt;code&gt;recipe&lt;/code&gt; package.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I split the input dataset into a training and testing set&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I build a random forest and an XGBoost model using the &lt;code&gt;parsnip&lt;/code&gt; package.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I use &lt;code&gt;tune&lt;/code&gt; package and tuning the hyper-paramters of the random forest and the XGBoost model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I use&lt;code&gt;rsample&lt;/code&gt; package to perform cross-validation and train both models.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I evaluate the performance of the trained models based on metrics from the &lt;code&gt;yardstick&lt;/code&gt; package and select the best model.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://tidymodels.github.io/yardstick/reference/index.html&#34; class=&#34;uri&#34;&gt;https://tidymodels.github.io/yardstick/reference/index.html&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Finally, I explain the predictions of the machine learning model in hope of finding interesting patterns that might tell us something about why a song becomes popular. Not that this step is not implemented as a part of the Tidymodel workflow.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;machine-learning-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine Learning&lt;/h2&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;pre-processing&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;bulding-the-ml-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bulding the ML models&lt;/h3&gt;
&lt;p&gt;first we need to specify the type of the model that we want to train and if necessary its hyper-paramters. Then we have to determine the mode of the ML task that we would like to solve. Our problem is a regression problem, so we set the mode as &lt;code&gt;regression&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;set the engine or the implementation of the model (Ranger)&lt;/p&gt;
&lt;p&gt;4.set the mode of the ML task (Regression)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploratory data analysis&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
 select(track_popularity, c(12:23)) %&amp;gt;% 
 correlate() %&amp;gt;% 
  network_plot(min_cor = 0.1,color = c(&amp;#39;#1a535c&amp;#39;,&amp;#39;#4ecdc4&amp;#39;,&amp;#39;#f7fff7&amp;#39;,&amp;#39;#ff6b6b&amp;#39;,&amp;#39;#ffe66d&amp;#39;)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Correlation method: &amp;#39;pearson&amp;#39;
## Missing treated using: &amp;#39;pairwise.complete.obs&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-what-makes-a-song-popular-an-explainable-machine-learning-approach/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
 ggplot(aes(track_popularity)) +
 geom_histogram(fill = &amp;#39;indianred&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-what-makes-a-song-popular-an-explainable-machine-learning-approach/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;shap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Shap&lt;/h2&gt;
&lt;div id=&#34;machine-learning-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Machine Learning&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#rf &amp;lt;- rand_forest(trees = 100, mode = &amp;#39;regression&amp;#39;) %&amp;gt;% 
 #set_engine(&amp;quot;randomForest&amp;quot;) %&amp;gt;% 
 #fit(Species ~. ,data = iris_training)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references-and-further-readings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References and further readings&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaylinpavlik.com/classifying-songs-genres/&#34; class=&#34;uri&#34;&gt;https://www.kaylinpavlik.com/classifying-songs-genres/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://konradsemsch.netlify.com/2019/10/testing-the-tune-package-from-tidymodels-analysing-the-relationship-between-the-upsampling-ratio-and-model-performance/&#34; class=&#34;uri&#34;&gt;https://konradsemsch.netlify.com/2019/10/testing-the-tune-package-from-tidymodels-analysing-the-relationship-between-the-upsampling-ratio-and-model-performance/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Optimal Rule Lists</title>
      <link>/post/2020-01-18-optimal-rule-lists/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-01-18-optimal-rule-lists/</guid>
      <description>


&lt;p&gt;Axiom
There is an inverse relationship between
model accuracy and model interpretability.&lt;/p&gt;
&lt;p&gt;This post is heavily inspired by the Decision Rules chapter from the Interpretable Machine Learning book by Christoph Molnar.&lt;/p&gt;
&lt;p&gt;Some machine learning researchers argue that we should pay more attention to interpretable machine learning instead of trying to design methods to explain black box models.
While reading almost any paper the field of explainable machine learning, you will notice that in that every paper almost always starts by arguing that there is a trade-off between accuracy and interpretability. It means that a more interpretable is less accurate and vice versa and for this reason we need to use more complex and black box models and then design methods to peek into them. However, Cynthia Rudin argues that actually there is no trade-off between these two concepts. On the contrary, interpretability can even help us increase the accuracy of a model becuase with an interpretable algorithm we better understand how the predictive performance of a model can be improved.&lt;/p&gt;
&lt;p&gt;Cynthia Rudin encourages machine learning practitioners and researchers to rather than trying to make black-box algorithms more build and use accurate interpretable machine learning models .
There are already a number of interpretable machine learning algorithms in the literature.
Decision trees and linear models are the two most popular classes of interpretable algorithms. Rule learning algorithms also belong to the class of interpretable algorithms. The aim of these algorithms is to learn decision rules from input data.&lt;/p&gt;
&lt;p&gt;Decision rules are expressed as IF-THEN statement.&lt;/p&gt;
&lt;p&gt;If the condition of the IF part holds true, we will make the prediction based on output of the THEN part.&lt;/p&gt;
&lt;p&gt;Decision rules are considered to be probably the most human-understandable prediction model.&lt;/p&gt;
&lt;p&gt;In many ways, decision rules resemble decision trees. In fact, we can write down a decision tree as a set of decision rules.&lt;/p&gt;
&lt;p&gt;Decision trees are highly scalable and powerful algorithms. But a decision tree is a greedy algorithm. For instance, the split at each node in a decision tree is determined by a greedy process. It means that the decision tree does not find an optimal solution and therefore, the optimal rule lists.&lt;/p&gt;
&lt;div id=&#34;how-to-bin&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to bin&lt;/h1&gt;
&lt;p&gt;optbin
santokura&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(OneR)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;OneR&amp;#39; was built under R version 3.6.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris_binned &amp;lt;- optbin(iris)
iris_binned&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Sepal.Length Sepal.Width Petal.Length    Petal.Width    Species
## 1     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 2     (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 3     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 4     (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 5     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 6     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 7     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 8     (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 9     (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 10    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 11    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 12    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 13    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 14    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 15   (5.41,6.25]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 16   (5.41,6.25]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 17    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 18    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 19   (5.41,6.25]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 20    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 21    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 22    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 23    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 24    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 25    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 26    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 27    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 28    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 29    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 30    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 31    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 32    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 33    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 34   (5.41,6.25]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 35    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 36    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 37   (5.41,6.25]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 38    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 39    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 40    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 41    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 42    (4.3,5.41]    (2,2.87] (0.994,2.46] (0.0976,0.791]     setosa
## 43    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 44    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 45    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 46    (4.3,5.41] (2.87,3.19] (0.994,2.46] (0.0976,0.791]     setosa
## 47    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 48    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 49    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 50    (4.3,5.41]  (3.19,4.4] (0.994,2.46] (0.0976,0.791]     setosa
## 51    (6.25,7.9]  (3.19,4.4]  (2.46,4.86]   (0.791,1.63] versicolor
## 52    (6.25,7.9]  (3.19,4.4]  (2.46,4.86]   (0.791,1.63] versicolor
## 53    (6.25,7.9] (2.87,3.19]  (4.86,6.91]   (0.791,1.63] versicolor
## 54   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 55    (6.25,7.9]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 56   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 57    (6.25,7.9]  (3.19,4.4]  (2.46,4.86]   (0.791,1.63] versicolor
## 58    (4.3,5.41]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 59    (6.25,7.9] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 60    (4.3,5.41]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 61    (4.3,5.41]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 62   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 63   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 64   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 65   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 66    (6.25,7.9] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 67   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 68   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 69   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 70   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 71   (5.41,6.25]  (3.19,4.4]  (2.46,4.86]     (1.63,2.5] versicolor
## 72   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 73    (6.25,7.9]    (2,2.87]  (4.86,6.91]   (0.791,1.63] versicolor
## 74   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 75    (6.25,7.9] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 76    (6.25,7.9] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 77    (6.25,7.9]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 78    (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5] versicolor
## 79   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 80   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 81   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 82   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 83   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 84   (5.41,6.25]    (2,2.87]  (4.86,6.91]   (0.791,1.63] versicolor
## 85    (4.3,5.41] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 86   (5.41,6.25]  (3.19,4.4]  (2.46,4.86]   (0.791,1.63] versicolor
## 87    (6.25,7.9] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 88    (6.25,7.9]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 89   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 90   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 91   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 92   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 93   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 94    (4.3,5.41]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 95   (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 96   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 97   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 98   (5.41,6.25] (2.87,3.19]  (2.46,4.86]   (0.791,1.63] versicolor
## 99    (4.3,5.41]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 100  (5.41,6.25]    (2,2.87]  (2.46,4.86]   (0.791,1.63] versicolor
## 101   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 102  (5.41,6.25]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 103   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 104   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 105   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 106   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 107   (4.3,5.41]    (2,2.87]  (2.46,4.86]     (1.63,2.5]  virginica
## 108   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 109   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 110   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 111   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 112   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 113   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 114  (5.41,6.25]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 115  (5.41,6.25]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 116   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 117   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 118   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 119   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 120  (5.41,6.25]    (2,2.87]  (4.86,6.91]   (0.791,1.63]  virginica
## 121   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 122  (5.41,6.25]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 123   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 124   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 125   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 126   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 127  (5.41,6.25]    (2,2.87]  (2.46,4.86]     (1.63,2.5]  virginica
## 128  (5.41,6.25] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 129   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 130   (6.25,7.9] (2.87,3.19]  (4.86,6.91]   (0.791,1.63]  virginica
## 131   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 132   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 133   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 134   (6.25,7.9]    (2,2.87]  (4.86,6.91]   (0.791,1.63]  virginica
## 135  (5.41,6.25]    (2,2.87]  (4.86,6.91]   (0.791,1.63]  virginica
## 136   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 137   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 138   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 139  (5.41,6.25] (2.87,3.19]  (2.46,4.86]     (1.63,2.5]  virginica
## 140   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 141   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 142   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 143  (5.41,6.25]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 144   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 145   (6.25,7.9]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 146   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 147   (6.25,7.9]    (2,2.87]  (4.86,6.91]     (1.63,2.5]  virginica
## 148   (6.25,7.9] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica
## 149  (5.41,6.25]  (3.19,4.4]  (4.86,6.91]     (1.63,2.5]  virginica
## 150  (5.41,6.25] (2.87,3.19]  (4.86,6.91]     (1.63,2.5]  virginica&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the XAI point of view, we are interested in measuring two metrics for rule lists:&lt;/p&gt;
&lt;p&gt;Accuracy&lt;/p&gt;
&lt;p&gt;Parsimony: Shorter rules are more preferable&lt;/p&gt;
&lt;div id=&#34;corels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;CORELS&lt;/h2&gt;
&lt;p&gt;Finding an optimal DT (or a set of rule lists) is an NP-hard problem. The CORELS algorithms developed by aims to find the optimal set of rules. To achieve this goal, CORLES uses pre-mined frequent patterns and optimization techniques.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantaged of rule lists&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Rule learning algorithms by design can be only trained on datasets with a discrete target variable. It means that they are only capable of dealing with classification problem and not regression. We can tackle this issue by discretizing the continuous target variable in regression problems. However, doing that results in information loss. Moreover, the input features to a rule learning algorithm must be categorical. Again we can solve this problem by binning continouose features but the same information loss will persist.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further Readings and Resources&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;p&gt;Refrences&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://shiring.github.io/machine_learning/2017/04/23/one_r&#34; class=&#34;uri&#34;&gt;https://shiring.github.io/machine_learning/2017/04/23/one_r&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
