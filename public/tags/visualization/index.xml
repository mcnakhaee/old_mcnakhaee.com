<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Visualization | Muhammad Chenariyan Nakhaee</title>
    <link>/tags/visualization/</link>
      <atom:link href="/tags/visualization/index.xml" rel="self" type="application/rss+xml" />
    <description>Visualization</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 04 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar.jpg</url>
      <title>Visualization</title>
      <link>/tags/visualization/</link>
    </image>
    
    <item>
      <title>Covid-19 Trends in the Netherlands</title>
      <link>/post/2020-11-04-covid-19-trends-in-the-netherlands/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-11-04-covid-19-trends-in-the-netherlands/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Two weeks ago, I made &lt;a href=&#34;https://www.linkedin.com/posts/muhammadcnakhaee_covid19-datavisualization-ggplot-activity-6726775611223764992-c_dk&#34;&gt;a visualization&lt;/a&gt; that shows how Covid-19 cases spread in the Netherlands from the beginning of March and how grim the situation looks. However, someone pointed out to the fact that the number of tests has increased significantly. It means that my plot may exaggerate the Covid-19 situation in the Netherlands. Unfortunately, I could not find testing data for each Dutch municipality. Instead, I decided to use hospitalization admission and deceased cases to see if we can indeed see a massive spread in the second wave of Covid-19 cases in the Netherlands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(CoronaWatchNL)
library(sf)
library(gganimate)
library(santoku)
library(lubridate)
library(gghighlight)
library(geofacet)
library(foreign)
theme_set(theme_void())
theme_update(
  #plot.background = element_rect(fill = &amp;#39;#FDF6E3&amp;#39;,color = &amp;#39;#FDF6E3&amp;#39;),
  text = element_text(family = &amp;#39;Poppins Light&amp;#39;),
  plot.subtitle = element_text(
    family = &amp;#39;Poppins Light&amp;#39;,
    size = 10,
    margin = margin(b = 10)
  ),
  plot.title = element_text(
    family = &amp;#39;Poppins Light&amp;#39;,
    size = 12,
    margin = margin(t = 10, b = 10)
  )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I created an R package called &lt;a href=&#34;https://github.com/mcnakhaee/CoronaWatchNL&#34;&gt;CoronaWarchNL&lt;/a&gt; that allows you to access a wide range of Covid-19 datasets. I’ll use this package in this post to get Covid-19 cases, hospital admissions, and deaths for Dutch municipalities.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;municipalBoundaries &amp;lt;- st_read(
    &amp;quot;https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?request=GetFeature&amp;amp;service=WFS&amp;amp;version=2.0.0&amp;amp;typeName=cbs_gemeente_2020_gegeneraliseerd&amp;amp;outputFormat=json&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `OGRGeoJSON&amp;#39; from data source `https://geodata.nationaalgeoregister.nl/cbsgebiedsindelingen/wfs?request=GetFeature&amp;amp;service=WFS&amp;amp;version=2.0.0&amp;amp;typeName=cbs_gemeente_2020_gegeneraliseerd&amp;amp;outputFormat=json&amp;#39; using driver `GeoJSON&amp;#39;
## Simple feature collection with 355 features and 5 fields
## geometry type:  MULTIPOLYGON
## dimension:      XY
## bbox:           xmin: 13565.4 ymin: 306846.2 xmax: 278026.1 ymax: 619352.4
## projected CRS:  Amersfoort / RD New&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;daily_cases_per_municpality &amp;lt;- get_daily_cases_per_municipality()
populatuon_per_region &amp;lt;- get_population_per_region()

daily_cases_per_municpality &amp;lt;- daily_cases_per_municpality %&amp;gt;%
  inner_join(populatuon_per_region, by = c(&amp;#39;Municipality_name&amp;#39; = &amp;#39;Regions&amp;#39;)) %&amp;gt;%
  mutate(
    Date_of_publication = as_date(Date_of_publication),
    avg_daily_total_cases = 100000 * as.numeric(Total_reported) / as.numeric(`Bevolking op 1 januari (aantal)`),
    avg_daily_hospital_admissions = 100000 * as.numeric(Hospital_admission) / as.numeric(`Bevolking op 1 januari (aantal)`),
    avg_daily_deceased = 100000 * as.numeric(Deceased) / as.numeric(`Bevolking op 1 januari (aantal)`)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I compute the weekly average number of Covid-19 cases, hospitalizations, and death per 100000 inhabitants in each municipality in the Netherlands. The following piece of code shows how I did this using R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weekly_cases &amp;lt;- daily_cases_per_municpality %&amp;gt;%
  mutate(week = round_date(Date_of_publication , unit = &amp;#39;week&amp;#39;))

weekly_cases_per_municpality &amp;lt;- weekly_cases %&amp;gt;%
  group_by(Municipality_name, week) %&amp;gt;%
  summarise(
    avg_weekly_total_cases = mean(avg_daily_total_cases),
    avg_weekly_hospital_admissions = mean(avg_daily_hospital_admissions),
    avg_weekly_deceased = mean(avg_daily_deceased)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(
    d_avg_weekly_total_cases = chop(avg_weekly_total_cases, c(0, 0, 0.5, 1, 5, 12, 20, 35, 55, 80, 100)),
    d_avg_hospital_admissions = chop(
      avg_weekly_hospital_admissions,
      c(0, 0, 0.5, 1, 2, 3, 5, 7, 9, 10, 15)),
    d_avg_weekly_deceased = chop(avg_weekly_deceased, c(0, 0, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 5)))

data_weekly &amp;lt;- municipalBoundaries %&amp;gt;%
  right_join(weekly_cases_per_municpality,
             by = c(statnaam = &amp;quot;Municipality_name&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will create an animation that shows how Covid-19 cases spread in the Netherlands and which municipality were and are hit hardest by the pandemic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;make_animation &amp;lt;- function(data, var_name, pal, title) {
  var_name &amp;lt;- rlang::enquo(var_name)
  data %&amp;gt;%
    #filter(week &amp;gt; &amp;#39;2020-10-01&amp;#39;) %&amp;gt;%
    ggplot() +
    geom_sf(aes(fill = !!var_name), color = &amp;#39;gray95&amp;#39;) +
    scale_fill_manual(values  = pal) +
    coord_sf(datum = NA) +
    labs(
      title = title,
      subtitle = &amp;#39;Date: {current_frame}&amp;#39;,
      fill = &amp;#39;Counts per 100000&amp;#39;,
      caption = &amp;#39;Source: RIVM&amp;#39;
    ) +
    transition_manual(week, cumulative = T) +
    ease_aes(&amp;quot;sine&amp;quot;) +
    enter_fade(alpha = 0.5) +
    exit_fade(alpha = 0.5)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first animation shows the number of infections in each municipality, from the start of the pandemic in February until recently. As you can see, the second wave, which began in late September, looks really terrifying. Note that there are some municipalities that no data is available for them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pal_cases &amp;lt;- c(
      &amp;#39;gray95&amp;#39;,
      &amp;#39;#fee440&amp;#39;,
      &amp;#39;#FFBA08&amp;#39;,
      &amp;#39;#FAA307&amp;#39;,
      &amp;#39;#F48C06&amp;#39;,
      &amp;#39;#E85D04&amp;#39;,
      &amp;#39;#DC2F02&amp;#39;,
      &amp;#39;#D00000&amp;#39;,
      &amp;#39;#9D0208&amp;#39;,
      &amp;#39;#6A040F&amp;#39;,
      &amp;#39;#370617&amp;#39;,
      &amp;#39;#03071e&amp;#39;
    )
make_animation(data_weekly,d_avg_weekly_total_cases,pal_cases,&amp;#39;The Average Weekly Number of Covid-19 Cases\nper 100000 Inhabitants in the Netherlands&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;cases.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we look at the number of hospital admissions we see a different story. It seems that the number of hospitalizations was higher during the first wave of Covid-19 compared to the second wave and mostly the southern parts of the Netherlands were hit harder than the rest of the Netherlands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pal_patients &amp;lt;- c(
      &amp;#39;gray95&amp;#39;,
      &amp;#39;#caf0f8&amp;#39;,
      &amp;#39;#ade8f4&amp;#39;,
      &amp;#39;#90e0ef&amp;#39;,
      &amp;#39;#48cae4&amp;#39;,
      &amp;#39;#00b4d8&amp;#39;,
      &amp;#39;#0096c7&amp;#39;,
      &amp;#39;#0077b6&amp;#39;,
      &amp;#39;#023e8a&amp;#39;,
      &amp;#39;#03045e&amp;#39;,
      &amp;#39;#03071e&amp;#39;
)
make_animation(data_weekly,d_avg_hospital_admissions,pal_patients,&amp;#39;The Average Weekly Number of Hospital Admissions\nper 100000 Inhabitants in the Netherlands&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;admissions.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The trend for deceased patients looks similar to of the hospital admission. The average numb of death during the first wave of Corona was higher than the average number of death during the second wave.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pal_deceased &amp;lt;- c(
      &amp;#39;gray95&amp;#39;,
      &amp;#39;#fdc5f5&amp;#39;,
     &amp;#39;#e0aaff&amp;#39;,
      &amp;#39;#c77dff&amp;#39;,
      &amp;#39;#9d4edd&amp;#39;,
      &amp;#39;#7b2cbf&amp;#39;,
      &amp;#39;#5a189a&amp;#39;,
      &amp;#39;#3c096c&amp;#39;,
      &amp;#39;#240046&amp;#39;,
      &amp;#39;#10002b&amp;#39;

)
make_animation(data_weekly,d_avg_weekly_deceased,pal_deceased,&amp;#39;The Average Weekly Number of Deceased Patients\nper 100000 Inhabitants in the Netherlands&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;deceased.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These different animations show us two distinct trends. On the one hand, we can see the number of confirmed cases rose rapidly during the second wave to affect almost all regions. On the other hand, the number of hospitalizations and deaths during the second wave slightly decreased. This might suggest that the rise in the number of cases is mainly driven by an increase in the number of tests. Alternatively, the virus might have become less deadly and severe.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How Easy Is It to Understand What Donald Trump Says?</title>
      <link>/post/2020-10-19-readability-of-trump-and-biden-speeches/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-10-19-readability-of-trump-and-biden-speeches/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Aside from their political differences, Donald Trump and Barack Obama have very contrasting personalities, traits and characters. Obama is known to be a great communicator and an articulate speaker whose speeches are used in English classes to show how one should speak proper English. On the other hand, Trump is not the most eloquent English speaker or US president in history. Every now and then, you can find a clip on the web where Donald Trump is being mocked for the way he speaks or mispronounces words. This is so obvious that even non-native English speakers can notice how Trump’s speeches are very simple and inarticulate. Of course, this was not a bad thing for Trump at all. Actually, almost every political analyst that you see on the news talks about the fact that a vast majority of Trump’s fervent supporters are not college-educated Americans. We can attribute this to the fact that he knows how to speak to his audience and his base supporters using their language (Although it is more likely that he cannot speak better English better than this level).&lt;/p&gt;
&lt;p&gt;This post will investigate how difficult it is to understand what each US politicians talked about in the 2020 US Election cycle. I will use several readability metrics that can help us compute text comprehensibility. A wide range of these measures are implemented in the &lt;a href=&#34;https://github.com/shivam5992/textstat&#34;&gt;{&lt;code&gt;textstat&lt;/code&gt;}&lt;/a&gt; python package, and it is super easy to calculate them using this package.&lt;/p&gt;
&lt;p&gt;I compiled a list of US Election-related speeches from rev.com and turned them into an R package called &lt;a href=&#34;https://github.com/mcnakhaee/us2020election&#34;&gt;&lt;code&gt;{us2020election}&lt;/code&gt;&lt;/a&gt;. I use this package as my data source for my analysis. Like some of my other posts, I use Python to perform the analysis and R to visualize my results. Now let’s get started by importing the necessary packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(reticulate)
library(ggthemes)
library(us2020election)
library(ggridges)
theme_set(theme_tufte())
theme_update(legend.position = &amp;#39;none&amp;#39;,
          text = element_text(family = &amp;#39;Lobser&amp;#39;),
          plot.title = element_text(margin = margin(t= 10,b= 5),family = &amp;#39;Lobser&amp;#39;),
          plot.subtitle = element_text(margin = margin(b= 10),family = &amp;#39;Lobser&amp;#39;),
          panel.background = element_rect(fill = &amp;#39;#FDF6E3&amp;#39;),
          plot.background = element_rect(fill = &amp;#39;#FDF6E3&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import pandas as pd 
import textstat&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are several readability measures for English text included in {&lt;code&gt;textstat&lt;/code&gt;}. Calculating these measures is very straightforward and easy. I will explain what each metric represents in more details.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;us_election_speeches = r.us_election_speeches
us_election_speeches[&amp;#39;Flesch_Reading_Ease_formula&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.flesch_reading_ease(x))
us_election_speeches[&amp;#39;gunning_fog&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.gunning_fog(x))
us_election_speeches[&amp;#39;smog_index&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.smog_index(x))
us_election_speeches[&amp;#39;automated_readability_index&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.automated_readability_index(x))
us_election_speeches[&amp;#39;coleman_liau_index&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.coleman_liau_index(x))
us_election_speeches[&amp;#39;linsear_write_formula&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.linsear_write_formula(x))
us_election_speeches[&amp;#39;dale_chall_readability_score&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.dale_chall_readability_score(x))
us_election_speeches[&amp;#39;text_standard&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.text_standard(x))
us_election_speeches[&amp;#39;text_standard_float&amp;#39;] = us_election_speeches[&amp;#39;text&amp;#39;].apply(lambda x: textstat.text_standard(x,float_output  = True))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look at the resulting dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us_election_speeches &amp;lt;- py$us_election_speeches 
us_election_speeches %&amp;gt;% 
glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 286
## Columns: 15
## $ speaker                      &amp;lt;chr&amp;gt; &amp;quot;Barack Obama&amp;quot;, &amp;quot;Mike Pence&amp;quot;, &amp;quot;Kamala ...
## $ title                        &amp;lt;chr&amp;gt; &amp;quot;Barack Obama Campaign Roundtable Even...
## $ text                         &amp;lt;chr&amp;gt; &amp;quot;Barack Obama: (00:01)\n… or the ’40s ...
## $ date                         &amp;lt;chr&amp;gt; &amp;quot;Oct 21, 2020&amp;quot;, &amp;quot;Oct 21, 2020&amp;quot;, &amp;quot;Oct 2...
## $ location                     &amp;lt;chr&amp;gt; &amp;quot;Philadelphia, Pennsylvania&amp;quot;, &amp;quot;Portsmo...
## $ type                         &amp;lt;chr&amp;gt; &amp;quot;Roundtable&amp;quot;, &amp;quot;Campaign Speech&amp;quot;, &amp;quot;Camp...
## $ Flesch_Reading_Ease_formula  &amp;lt;dbl&amp;gt; 78.38, 67.99, 65.35, 85.99, 71.04, 81....
## $ gunning_fog                  &amp;lt;dbl&amp;gt; 8.80, 9.32, 10.80, 5.37, 8.30, 7.31, 5...
## $ smog_index                   &amp;lt;dbl&amp;gt; 9.8, 11.5, 11.6, 8.1, 10.4, 8.7, 8.2, ...
## $ automated_readability_index  &amp;lt;dbl&amp;gt; 9.0, 10.8, 11.5, 5.3, 8.8, 6.9, 5.5, 5...
## $ coleman_liau_index           &amp;lt;dbl&amp;gt; 7.95, 9.11, 8.71, 6.48, 8.12, 6.90, 6....
## $ linsear_write_formula        &amp;lt;dbl&amp;gt; 5.375000, 5.333333, 11.666667, 15.0000...
## $ dale_chall_readability_score &amp;lt;dbl&amp;gt; 5.77, 5.75, 6.27, 5.18, 5.65, 5.66, 5....
## $ text_standard                &amp;lt;chr&amp;gt; &amp;quot;8th and 9th grade&amp;quot;, &amp;quot;8th and 9th grad...
## $ text_standard_float          &amp;lt;dbl&amp;gt; 9, 9, 12, 6, 8, 6, 6, 5, 11, 6, 5, 7, ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I am going to visualize the changes in the distribution of speech complexity for each politician. To make things more, I will select a list of politicians that I’d like to analyze in this post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;speakers &amp;lt;- c(&amp;#39;Barack Obama&amp;#39;,&amp;#39;Pete Buttigieg&amp;#39;,&amp;#39;Mike Pence&amp;#39;,&amp;#39;Elizabeth Warren&amp;#39;,&amp;#39;Bernie Sanders&amp;#39;,&amp;#39;Donald Trump&amp;#39;,&amp;#39;Kamala Harris&amp;#39;,&amp;#39;Joe Biden&amp;#39;,&amp;#39;Mike Bloomberg&amp;#39;)
custom_palette &amp;lt;-c(
    &amp;#39;Mike Bloomberg&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Amy Klobuchar&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Joe Biden&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Pete Buttigieg&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Elizabeth Warren&amp;#39; =  &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Barack Obama&amp;#39;  = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Bernie Sanders&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Kamala Harris&amp;#39; = &amp;#39;#4E79A7&amp;#39;,
    &amp;#39;Donald Trump&amp;#39;  = &amp;#39;#E15759&amp;#39; ,
     &amp;#39;Mike Pence&amp;#39; = &amp;#39;#E15759&amp;#39; 
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, I created a function to make ridge plots for each metric easier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot &amp;lt;- function(metric = Flesch_Reading_Ease_formula,subtitle = subtitle) {
  metrics &amp;lt;- rlang::enquo(metric)
  us_election_speeches %&amp;gt;%
    separate_rows(speaker, sep = &amp;#39;,&amp;#39;) %&amp;gt;%
    filter(speaker %in% speakers, type != &amp;#39;Debate&amp;#39;) %&amp;gt;%
    add_count(speaker) %&amp;gt;%
    ggplot() +
    geom_density_ridges(aes(
      x = !!metrics ,
      y = speaker,
      fill = speaker
    )) +
    labs(x = &amp;#39;&amp;#39;, y = &amp;#39;&amp;#39;,title = &amp;quot;How Easy Is It to Comprehend Different US Politicians?&amp;quot;,subtitle = str_wrap(subtitle,width = 100)) +
    scale_fill_manual(values = custom_palette) 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s look at several readability measure in more depth.&lt;/p&gt;
&lt;div id=&#34;flesch-reading-ease-scores&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Flesch Reading Ease scores&lt;/h3&gt;
&lt;p&gt;The first readability score that I will look at is based on the Flesch Reading Ease formula. It computes the number of syllables to determine how easy a piece of text is. The maximum value of Flesch Reading Ease is 122, and there is no minimum value for it. Higher Flesch Reading Ease scores indicate that the text (speech) is easier to understand by the audience. In our case, it would show how sophisticated each politician is in terms of language use. You can find more about this metric on &lt;a href=&#34;https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests&#34;&gt;Wikipedia&lt;/a&gt;!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(Flesch_Reading_Ease_formula ,
            subtitle = &amp;#39;The Flesch Reading Ease scores measure the complexity of a text document. Higher scores indicate a text is easier to comprehend.&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;we can interpret the scores using the following table:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;13%&#34; /&gt;
&lt;col width=&#34;20%&#34; /&gt;
&lt;col width=&#34;66%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Score&lt;/th&gt;
&lt;th&gt;School level&lt;/th&gt;
&lt;th&gt;Notes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;100.00–90.00&lt;/td&gt;
&lt;td&gt;5th grade&lt;/td&gt;
&lt;td&gt;Very easy to read. Easily understood by an average 11-year-old student.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;90.0–80.0&lt;/td&gt;
&lt;td&gt;6th grade&lt;/td&gt;
&lt;td&gt;Easy to read. Conversational English for consumers.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;80.0–70.0&lt;/td&gt;
&lt;td&gt;7th grade&lt;/td&gt;
&lt;td&gt;Fairly easy to read.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;70.0–60.0&lt;/td&gt;
&lt;td&gt;8th &amp;amp; 9th grade&lt;/td&gt;
&lt;td&gt;Plain English. Easily understood by 13- to 15-year-old students.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;60.0–50.0&lt;/td&gt;
&lt;td&gt;10th to 12th grade&lt;/td&gt;
&lt;td&gt;Fairly difficult to read.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;50.0–30.0&lt;/td&gt;
&lt;td&gt;College&lt;/td&gt;
&lt;td&gt;Difficult to read.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;30.0–10.0&lt;/td&gt;
&lt;td&gt;College graduate&lt;/td&gt;
&lt;td&gt;Very difficult to read. Best understood by university graduates.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;10.0–0.0&lt;/td&gt;
&lt;td&gt;Professional&lt;/td&gt;
&lt;td&gt;Extremely difficult to read. Best understood by university graduates.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;gunning-fog-index&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Gunning fog index&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Gunning_fog_index&#34;&gt;The Gunning fog index&lt;/a&gt; is another metric to measure the complexity of a text document. It shows how many years of education one might need to understand a piece of text. Larger values of the Gunning fog index correspond to more difficult writings.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(gunning_fog,subtitle = &amp;#39;The Gunning fog index measure the complexity of a text document. Larger values of the Gunning fog index correspond to more difficult writings.&amp;#39; )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-smog-index&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The SMOG index&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/SMOG&#34;&gt;The SMOG index&lt;/a&gt; computes the ratio of polysyllables (words with three or more syllables) in sentences to determine text complexity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(smog_index,subtitle = &amp;#39;The SMOG index measure the complexity of a text document. Larger values of the SMOG index indicate more difficult writings.&amp;#39; )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linsear-write-formula&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linsear Write Formula&lt;/h3&gt;
&lt;p&gt;Like previous the metric, &lt;a href=&#34;https://en.wikipedia.org/wiki/Linsear_Write&#34;&gt;the Linsear Write Formula&lt;/a&gt; uses words with three or more syllables to compute text readability. It also relies on the sentence length to measure how difficult reading a text could be.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(linsear_write_formula, subtitle = &amp;#39;The Linsear Write Formula measure the complexity of a text document. Larger values indicate more difficult writings.&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dale-chall-readability-score&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Dale–Chall_readability_formula&#34;&gt;Dale-Chall Readability Score&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This metric is different from the other metrics that we have talked about. It uses a dictionary of 3000 words that are easy to read and understand for a fourth-grade student. So, Words that are not in this dictionary are considered to be complex. The higher the Dale-Chall Score is, the more difficult it is to read a text.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(dale_chall_readability_score,subtitle = &amp;#39;The Dale-Chall Readability Score measure the complexity of a text document. The higher the Dale-Chall Score is, the more difficult it is to read a text.&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;960&#34; /&gt;
### A unified readability&lt;/p&gt;
&lt;p&gt;We introduced several readability metrics, but each one of them might give us a slightly different result. There is a way in &lt;code&gt;textstats&lt;/code&gt; to combine all these metrics and have a single readability metric.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us_election_speeches %&amp;gt;%
  filter(speaker %in% speakers) %&amp;gt;%
  mutate(text_standard = str_replace(text_standard,&amp;#39; and &amp;#39;,&amp;#39;-&amp;#39;),
        text_standard = factor(
    text_standard,
    levels = c(
      &amp;#39;4th-5th grade&amp;#39;,
      &amp;#39;5th-6th grade&amp;#39;,
      &amp;#39;6th-7th grade&amp;#39;,
      &amp;#39;7th-8th grade&amp;#39;,
      &amp;#39;8th-9th grade&amp;#39;,
      &amp;#39;9th-10th grade&amp;#39;,
      &amp;#39;10th-11th grade&amp;#39;,
      &amp;#39;11th-12th grade&amp;#39;,
      &amp;#39;12th-13th grade&amp;#39;,
      &amp;#39;14th-15th grade&amp;#39;
    )
  )) %&amp;gt;%
  count(speaker, text_standard) %&amp;gt;%
  mutate(n = n + 1) %&amp;gt;%
  ggplot()  +
  geom_col(aes(x = text_standard , y =  n, fill = speaker)) +
  labs(x = &amp;#39;&amp;#39;, y = &amp;#39;Number of Speeches&amp;#39;, title = &amp;quot;How Easy Is It to Understand &amp;#39;Trump&amp;#39;s Speeches?&amp;quot;,
       subtitle = &amp;#39;Based on several readability tests, the education level that one needs to comprehend the 2020 Election speeches by different US politicians is illustrated in this plot.&amp;#39; ) +
  scale_fill_manual(values = custom_palette) +
  scale_y_log10() +
  facet_wrap(~ speaker, ncol = 1) +
  theme(axis.text  = element_text(size = 13),
        axis.title.y = element_text(size = 15,margin = margin(r = 10,l = 10)),
        plot.title = element_text(size = 20,margin = margin(b = 10,t = 10)),
        plot.subtitle = element_text(size = 14,margin = margin(b = 10)),
        strip.text = element_text(size = 15))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, we can observe that Trump never gave a speech to an audience with difficulty more than the 7th or 8th grade. We can also convert this readability metric to numbers to visualize and compare it to other metrics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_plot(text_standard_float,subtitle = &amp;#39;The complexity of a text document were measured based on several readability metrics where larger values indicate more difficult writings.&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-19-readability-of-trump-and-biden-speeches/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We can consistently see that Trump speeches are less sophisticated and less complex than the speeches given by the rest of politicians. We can attribute this to his lack of sophistication in terms of language, the fact that he knows how can speak to his audience or both. Also, we can notice that Mike Pence and Barack Obama seem to use a more an advanced language in their speeches.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Which Presidential Debate Was More Chaotic?</title>
      <link>/post/2020-10-15-which-presidential-debate-was-more-chaotic/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-10-15-which-presidential-debate-was-more-chaotic/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Many people watched the first Presidential Debate between Biden and Trump and thought that this debate was chaotic, full of vulgar language, interruptions, and in a word, really ugly! Some people even consider this debate as &lt;a href=&#34;https://www.politico.com/news/2020/09/30/the-worst-presidential-debate-in-history-423765&#34;&gt;the worst debate in the modern history of US Presidential Elections!&lt;/a&gt; Four years ago, Trump was also a presidential candidate and ran against Hillary Clinton. The Presidential Debates in 2016 were not exceptionally friendly or civilized. So, the question is what made the 2020 first debate unique and chaotic in many people’s minds. In this blog post, I will investigate this question and compare the 2020 and 2016 Presidential debates and the Vice Presidential debates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # metapackage of all tidyverse packages
library(lubridate)
library(readxl)
library(ggthemes)
library(showtext)
library(plotly)
font_add_google(&amp;quot;Lobster&amp;quot;, &amp;quot;Lobster&amp;quot;)
font_add_google(&amp;quot;Overpass&amp;quot;, &amp;quot;Overpass&amp;quot;)
options(repr.plot.width=20, repr.plot.height=15)

biden_col &amp;lt;- &amp;#39;#118ab2&amp;#39;
trump_col &amp;lt;- &amp;#39;#ef476f&amp;#39;
wallace_col &amp;lt;- &amp;#39;#ffd166&amp;#39;
cross_talk_col &amp;lt;- &amp;#39;#06d6a0&amp;#39;
moderator &amp;lt;- &amp;#39;#ffd166&amp;#39;
audience &amp;lt;- &amp;#39;#e36414&amp;#39;
clinton_col &amp;lt;- &amp;#39;#118ab2&amp;#39;
text_col &amp;lt;-  &amp;#39;gray80&amp;#39;

theme_set(theme_void())
theme_update(  
    legend.position = &amp;#39;top&amp;#39;,
    legend.text = element_text(
      size = 20,
      family = &amp;#39;Lobster&amp;#39;,
      color = text_col
    ),
    text = element_text(family = &amp;#39;Lobster&amp;#39;, color = text_col),
    plot.title = element_text(
      size = 40,
      margin = margin(b = 40, t = 50, l = 50),
      hjust = 0.5,
      family = &amp;#39;Lobster&amp;#39;,
      color = text_col
    ),
    plot.caption = element_text(
      size = 20,
      ,
      margin = margin(b = 50, t = 50),
      family = &amp;#39;Lobster&amp;#39;,
      color = text_col
    ),
    plot.background = element_rect(fill = &amp;#39;gray14&amp;#39;),
    panel.background = element_rect(fill = &amp;#39;gray14&amp;#39;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;biden-and-trumps-first-debate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Biden and Trump’s first debate&lt;/h3&gt;
&lt;p&gt;Let us look at the first debate between Trump and Biden and how much each candidate used to speak uninterrupted by the other candidate or the moderator. I used &lt;a href=&#34;https://www.kaggle.com/rmphilly18/vice-presidential-debate-2020-transcript&#34;&gt;this dataset which is available on Kaggle&lt;/a&gt; to computed how many seconds Trump and Biden talked without being cut off by the other candidate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;presidential_debate_2020 &amp;lt;- read_delim(&amp;#39;presidential_debate_2020.csv&amp;#39;,
                        delim = &amp;#39;\t&amp;#39;,
                        col_types = list(col_character(),
                                         col_character(),
                                         col_character(),
                                         col_character(),
                                         col_integer(),
                                         col_integer(),
                                         col_double(),
                                         col_integer()))
presidential_debate_2020 &amp;lt;- presidential_debate_2020 %&amp;gt;% 
  mutate(minutes = if_else(nchar(time)&amp;lt;6,paste(&amp;#39;00:&amp;#39;,time,sep = &amp;#39;&amp;#39;),time),
         minutes = paste(&amp;#39;2020-09-29&amp;#39;,minutes,sep = &amp;#39;&amp;#39;),
         minutes = lubridate::ymd_hms(minutes),
         speaker = if_else(str_detect(speaker , &amp;#39;Chris Wallace&amp;#39;),&amp;#39;Chris Wallace (Moderator)&amp;#39;,speaker),
          ) %&amp;gt;% 
    mutate(minute_start = lag(minutes,n= 1),
         duration =minutes - minute_start,
         duration = lead(duration,n =1),
         seconds_in_end = lead(seconds_in),
         text = str_wrap(text,width =30))


presidential_debate_2020[1,5] &amp;lt;- 0

glimpse(presidential_debate_2020)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 788
## Columns: 12
## $ speaker        &amp;lt;chr&amp;gt; &amp;quot;Chris Wallace (Moderator)&amp;quot;, &amp;quot;Chris Wallace (Moderat...
## $ text           &amp;lt;chr&amp;gt; &amp;quot;Good evening from the Health\nEducation Campus of C...
## $ url            &amp;lt;chr&amp;gt; &amp;quot;https://www.rev.com/transcript-editor/shared/C-8bDp...
## $ time           &amp;lt;chr&amp;gt; &amp;quot;1:20&amp;quot;, &amp;quot;2:10&amp;quot;, &amp;quot;2:49&amp;quot;, &amp;quot;2:51&amp;quot;, &amp;quot;2:51&amp;quot;, &amp;quot;3:11&amp;quot;, &amp;quot;4:0...
## $ seconds_in     &amp;lt;int&amp;gt; 0, 130, 169, 171, 171, 191, 241, 293, 322, 329, 334,...
## $ seconds_spoken &amp;lt;int&amp;gt; 50, 39, 2, 0, 20, 50, 52, 29, 7, 5, 2, 36, 56, 26, 2...
## $ words_per_min  &amp;lt;dbl&amp;gt; 148.8000, 156.9231, 120.0000, NA, NA, 159.6000, 180....
## $ num_words      &amp;lt;int&amp;gt; 124, 102, 4, 4, 2, 133, 156, 98, 15, 16, 3, 117, 157...
## $ minutes        &amp;lt;dttm&amp;gt; 2020-09-29 00:01:20, 2020-09-29 00:02:10, 2020-09-2...
## $ minute_start   &amp;lt;dttm&amp;gt; NA, 2020-09-29 00:01:20, 2020-09-29 00:02:10, 2020-...
## $ duration       &amp;lt;drtn&amp;gt; 50 secs, 39 secs, 2 secs, 0 secs, 20 secs, 50 secs,...
## $ seconds_in_end &amp;lt;int&amp;gt; 130, 169, 171, 171, 191, 241, 293, 322, 329, 334, 33...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;presidential_debate_2020 %&amp;gt;%
  ggplot(aes(
    x = seconds_in,
    y = 1,
    xend = seconds_in_end,
    yend = 1,
    color = speaker
  )) +
  geom_segment(size = 40, alpha = 0.7) +

  guides(color = guide_legend(override.aes = list(size = 25))) +
  scale_color_manual(values = c(wallace_col, trump_col, biden_col)) +
  scale_y_continuous(limits = c(0.85, 1.13)) +
  labs(
    x = &amp;#39;&amp;#39;,
    y = &amp;#39;&amp;#39;,
    title = &amp;#39;How Did The First US Presidential Debate Go?&amp;#39;,
    #subtitle = &amp;#39;This plot illustrates how much time each presidential candidate spoke &amp;#39;,
    fill = &amp;#39;&amp;#39;,
    color = &amp;#39;&amp;#39;  ) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-15-which-presidential-debate-was-more-chaotic/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;clinton-vs.-trump&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Clinton vs. Trump&lt;/h3&gt;
&lt;p&gt;This plot clearly shows that there were many interruptions during the first debate! It also shows that it was Trump who interrupted most in the debate. To give it more context, let us compare it to the 2016 Debates between Trump and Clinton. The transcripts of these debates are available in &lt;a href=&#34;https://www.kaggle.com/mrisdal/2016-us-presidential-debates&#34;&gt;this dataset that I found on Kaggle&lt;/a&gt;. However, this dataset does not include information about how many seconds or minutes each candidate spent speaking in the debates. So, I decided to use the number of words each candidate spoke to measure continuity in their speeches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;debate_2016 &amp;lt;- read_csv(&amp;#39;presidential_debate_2016.csv&amp;#39;)
debate_2016 &amp;lt;-debate_2016 %&amp;gt;% 
    mutate(Text = as.character(Text),
    num_chars = str_length(Text),
    num_word = str_count(Text),
    Speaker = case_when(Speaker == &amp;#39;CANDIDATES&amp;#39;~&amp;#39;Crosstalk&amp;#39;,
                        Speaker == &amp;#39;QUESTION&amp;#39;~&amp;#39;Question&amp;#39;,
                        Speaker %in% c(&amp;#39;Cooper&amp;#39;, &amp;#39;Holt&amp;#39;,&amp;#39;Wallace&amp;#39;,&amp;#39;Raddatz&amp;#39;,&amp;#39;Quijano&amp;#39;) ~&amp;#39;Moderator&amp;#39;,
                        TRUE ~ Speaker))

presidential_debate_2016 &amp;lt;- debate_2016 %&amp;gt;% 
  filter(!Speaker %in% c(&amp;#39;Kaine&amp;#39;,&amp;#39;Pence&amp;#39;),
         Date != &amp;#39;10/4/16&amp;#39;)


first_debate &amp;lt;- presidential_debate_2016%&amp;gt;% 
  filter(Date == &amp;#39;9/26/16&amp;#39;)
second_debate &amp;lt;- presidential_debate_2016 %&amp;gt;% 
  filter(Date == &amp;#39;10/9/16&amp;#39;)
third_debate &amp;lt;- presidential_debate_2016 %&amp;gt;% 
  filter(Date == &amp;#39;10/19/2016&amp;#39;)

glimpse(presidential_debate_2016)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1,028
## Columns: 6
## $ Line      &amp;lt;dbl&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...
## $ Speaker   &amp;lt;chr&amp;gt; &amp;quot;Moderator&amp;quot;, &amp;quot;Audience&amp;quot;, &amp;quot;Clinton&amp;quot;, &amp;quot;Audience&amp;quot;, &amp;quot;Moderato...
## $ Text      &amp;lt;chr&amp;gt; &amp;quot;Good evening from Hofstra University in Hempstead, New Y...
## $ Date      &amp;lt;chr&amp;gt; &amp;quot;9/26/16&amp;quot;, &amp;quot;9/26/16&amp;quot;, &amp;quot;9/26/16&amp;quot;, &amp;quot;9/26/16&amp;quot;, &amp;quot;9/26/16&amp;quot;, &amp;quot;9...
## $ num_chars &amp;lt;int&amp;gt; 1257, 10, 20, 10, 17, 10, 1115, 820, 1018, 171, 1570, 515...
## $ num_word  &amp;lt;int&amp;gt; 1257, 10, 20, 10, 17, 10, 1115, 820, 1018, 171, 1570, 515...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_debate&amp;lt;- first_debate %&amp;gt;% 
  mutate(cumsum_nwords = cumsum(num_word),
         cum_sum_lag = lag(cumsum_nwords),
         debate = &amp;#39;First Debate&amp;#39;)

first_debate[1,7] &amp;lt;- 0

second_debate&amp;lt;- second_debate %&amp;gt;% 
  mutate(cumsum_nwords = cumsum(num_word),
         cum_sum_lag = lag(cumsum_nwords),
         debate = &amp;#39;Second Debate&amp;#39;)

second_debate[1,7] &amp;lt;- 0

third_debate&amp;lt;- third_debate %&amp;gt;% 
  mutate(cumsum_nwords = cumsum(num_word),
         cum_sum_lag = lag(cumsum_nwords),
         debate = &amp;#39;Third Debate&amp;#39;)

third_debate[1,7] &amp;lt;- 0


presidential_debates_2016 &amp;lt;- bind_rows(first_debate,second_debate ,third_debate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;presidential_debates_2016 %&amp;gt;%
ggplot(aes(
    x = cum_sum_lag,
    y = 1,
    xend = cumsum_nwords,
    yend = 1,
    color = Speaker
  )) +
  geom_segment(size = 40, alpha = 0.7) +

  guides(color = guide_legend(override.aes = list(size = 18))) +
  scale_color_manual(values = c(&amp;#39;Moderator&amp;#39; = moderator ,&amp;#39;Trump&amp;#39; = trump_col  ,
                               &amp;#39;Clinton&amp;#39; = clinton_col ,
                              &amp;#39;Crosstalk&amp;#39;  =&amp;#39;#9d4edd&amp;#39;,
                              &amp;#39;Audience&amp;#39; =  audience ,
                              &amp;#39;Question&amp;#39;  =  &amp;#39;#e85d04&amp;#39;)) +
  scale_y_continuous(limits = c(0.85, 1.13)) +
  labs(
    x = &amp;#39;&amp;#39;,
    y = &amp;#39;&amp;#39;,
    title = &amp;#39;How Did 2016 US Presidential Debates Go?&amp;#39;,
    fill = &amp;#39;&amp;#39;,
    color = &amp;#39;&amp;#39;,
    caption =  
  ) +
  facet_wrap(~debate,nrow = 3) +
  theme(strip.text = element_text(size = 15))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-15-which-presidential-debate-was-more-chaotic/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, the debates between Trump and Clinton were also wild, but they were less anarchic than the debate between Biden and Trump. For, there were fewer disruptions in those debates compared to what we saw in the 2020 plot.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vice-presidential-debates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vice Presidential debates&lt;/h3&gt;
&lt;p&gt;Now let’s look at the debates between the Vice Presidential candidates. Usually, these debates are more civilized and less heated as they attract less attention.&lt;/p&gt;
&lt;div id=&#34;harris-vs.-pence&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Harris vs. Pence&lt;/h4&gt;
&lt;p&gt;I found &lt;a href=&#34;https://www.kaggle.com/headsortails/us-election-2020-presidential-debates&#34;&gt;a dataset of the 2020 VP debate on Kaggle&lt;/a&gt;. Again, here I used the same approach that I used for the 2016 debate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vice_presidential_debate_2020 &amp;lt;- read_csv(&amp;#39;vice_presidential_debate_2020.csv&amp;#39;)
vice_presidential_debate_2020 &amp;lt;- vice_presidential_debate_2020 %&amp;gt;%
mutate(num_chars = str_length(text ),
       cumsum_nwords = cumsum(num_chars),
      cum_sum_lag = lag(cumsum_nwords))

vice_presidential_debate_2020[1,6] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vice_presidential_debate_2020 %&amp;gt;%
ggplot(aes(
    x = cum_sum_lag,
    y = 1,
    xend = cumsum_nwords,
    yend = 1,
    color = speaker 
  )) +
  geom_segment(size = 40, alpha = 0.7) +

  guides(color = guide_legend(override.aes = list(size = 18))) +
  scale_color_manual(values = c(&amp;quot;Susan Page&amp;quot; = moderator ,&amp;#39;Mike Pence&amp;#39; = trump_col  ,
                               &amp;#39;Kamala Harris&amp;#39; = clinton_col )) +
  scale_y_continuous(limits = c(0.85, 1.13)) +
  labs(
    x = &amp;#39;&amp;#39;,
    y = &amp;#39;&amp;#39;,
    title = &amp;#39;How Did 2020 US Vice-Presidential Debates Go?&amp;#39;,
    fill = &amp;#39;&amp;#39;,
    color = &amp;#39;&amp;#39;,
    caption =  
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-15-which-presidential-debate-was-more-chaotic/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vice-presidential-debate&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2016 Vice Presidential debate&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vp_debates &amp;lt;- debate_2016 %&amp;gt;% 
  filter(Date == &amp;#39;10/4/16&amp;#39;) %&amp;gt;% 
  mutate(cumsum_nwords = cumsum(num_word),
         cum_sum_lag = lag(cumsum_nwords)) 
  
vp_debates[1,5] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vp_debates %&amp;gt;%
ggplot(aes(
    x = cum_sum_lag,
    y = 1,
    xend = cumsum_nwords,
    yend = 1,
    color = Speaker 
  )) +
  geom_segment(size = 40, alpha = 0.7) +

  guides(color = guide_legend(override.aes = list(size = 18))) +
  scale_color_manual(values = c(&amp;#39;Moderator&amp;#39; = moderator ,&amp;#39;Pence&amp;#39; = trump_col  ,
                               &amp;#39;Kaine&amp;#39; = clinton_col ,
                              &amp;#39;Crosstalk&amp;#39;  =&amp;#39;#9d4edd&amp;#39;,
                              &amp;#39;Audience&amp;#39; =  audience )) +
  scale_y_continuous(limits = c(0.85, 1.13)) +
  labs(
    x = &amp;#39;&amp;#39;,
    y = &amp;#39;&amp;#39;,
    title = &amp;#39;How Did 2016 US Vice-Presidential Debates Go?&amp;#39;,
    fill = &amp;#39;&amp;#39;,
    color = &amp;#39;&amp;#39;,
    caption =  
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-15-which-presidential-debate-was-more-chaotic/index.en_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, we can see that Pence and Kaine cut each other off many times during the VP debate. However, we can also observe that they could speak uninterrupted on some occasions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Happiest, Saddest, Most Energetic and Most Popular Persian Singers on Spotify</title>
      <link>/post/happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;I am a music lover, and like my other hobbies, I am really interested in applying data science methods to it. A few months ago, I participated in the third week of the TidyTuesday project, where I made a map of Spotify songs based on audio features and a dimensionality reduction algorithm called UMAP. Since then, I have been using Spotify’s Web API to collect data, and recently, I decided to look at some of my favorite Iranian artists and their songs on Spotify. We have different genres and types of music, and while pop and rap are very popular among the younger generation, I like the traditional style more. Nevertheless, I was always curious to understand how different traditional music and pop music are. For this reason, that I like the most These are a few questions that I would like to answer:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;How different audio features can be among top Persian singers?&lt;/li&gt;
&lt;li&gt;What are the most danceable and least danceable Persian songs?&lt;/li&gt;
&lt;li&gt;Who is the most popular Persian singer, and what is the most popular song?&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(kableExtra)
library(tidyverse)
library(googlesheets4)
library(tidymodels)
library(gghighlight)
library(hrbrthemes)
library(ggthemes)
library(ggrepel)
library(ggalt)
library(extrafont)
library(ggtext)
library(ggforce)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-collection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Collection&lt;/h2&gt;
&lt;p&gt;I compiled a list of Persian Singers manually and collected information about their available songs on Spotify using the &lt;code&gt;spotifyr&lt;/code&gt; package in R which lets us use R to access the Spotify’s API. This process was cumbersome as sometimes I was not getting what I was looking for. For instance, sometimes, songs that belonged to another random artist were retrieved. For each singer, we can only retrieve the top 10 popular songs. It means that the rest of the songs have no popularity scores. In the end, I collected various kinds of information about more than 10000 songs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop &amp;lt;- read_csv(&amp;#39;https://raw.githubusercontent.com/mcnakhaee/datasets/master/Persian_Songs_Spotify.csv&amp;#39;)

head(songs_audio_plus_pop) %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
track_id
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
poet
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lyrics
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lyrics source
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
disc_number
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
duration_ms
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
explicit
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
track_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
track_name_farsi
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
artist_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
artist_name_farsi
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
popularity
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
track_number
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
album_href
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
album_id
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
album_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
album_release_date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
album_total_tracks
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
album_release_year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
track_href
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
danceability
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
energy
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
key
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
loudness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mode
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
speechiness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
acousticness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
instrumentalness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
liveness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
valence
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tempo
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
time_signature
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
key_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
mode_name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
key_mode
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
artist_id
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lyrics_1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
poet_1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lyric source
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
genre
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
31iPeC6I0AiRW8InOxNKzm
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
446880
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Ghazale Taze
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6GcmAWrnnMb2BuVriPhBLa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Va Eshgh Amad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2020-02-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/31iPeC6I0AiRW8InOxNKzm&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/31iPeC6I0AiRW8InOxNKzm&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.437
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.390
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-7.170
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0299
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.839
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.51e-05
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1360
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.330
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
131.913
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4Fi46ha8teWYTwk0b8fNPi
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
851920
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Ayeeneye Hosn
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6GcmAWrnnMb2BuVriPhBLa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Va Eshgh Amad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2020-02-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/4Fi46ha8teWYTwk0b8fNPi&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/4Fi46ha8teWYTwk0b8fNPi&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.379
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.146
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-10.008
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0414
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.970
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.60e-04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0812
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.346
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
105.634
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
major
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F major
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0lQAe6EslKA7CUsS7SCW6Q
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
293160
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tarke Eshgh
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6GcmAWrnnMb2BuVriPhBLa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Va Eshgh Amad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2020-02-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/0lQAe6EslKA7CUsS7SCW6Q&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/0lQAe6EslKA7CUsS7SCW6Q&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.437
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.392
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0349
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.664
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.07e-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.501
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
94.651
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6dAFmJdVsKk5ksCpGqnKgO
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
648720
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Moghbacheye Bade Foroosh
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6GcmAWrnnMb2BuVriPhBLa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Va Eshgh Amad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2020-02-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/6dAFmJdVsKk5ksCpGqnKgO&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/6dAFmJdVsKk5ksCpGqnKgO&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.488
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.138
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-12.287
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0451
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.915
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.58e-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2120
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.445
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
110.967
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
D
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
D minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4VSDJGyEdSMB8UL4fDSCvv
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
273480
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Bigharar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6GcmAWrnnMb2BuVriPhBLa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Va Eshgh Amad
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2020-02-03
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2020
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/4VSDJGyEdSMB8UL4fDSCvv&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/4VSDJGyEdSMB8UL4fDSCvv&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.301
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.443
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-5.702
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0334
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.657
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.50e-06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1200
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.410
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
148.053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1tqsOZ3fGtMXL0r2ySBpvA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
260754
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Negar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Salar Aghili
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;lt;U+0633&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+0627&amp;gt;&amp;lt;U+0631&amp;gt; &amp;lt;U+0639&amp;gt;&amp;lt;U+0642&amp;gt;&amp;lt;U+06CC&amp;gt;&amp;lt;U+0644&amp;gt;&amp;lt;U+06CC&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
09Hepb4NioQ6sO87tsDyiz
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Negar
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2019-10-30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2019
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://api.spotify.com/v1/tracks/1tqsOZ3fGtMXL0r2ySBpvA&#34; class=&#34;uri&#34;&gt;https://api.spotify.com/v1/tracks/1tqsOZ3fGtMXL0r2ySBpvA&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.577
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.366
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-6.668
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0368
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.834
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.90e-06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1110
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.367
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
77.453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C minor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;overall-song-features&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overall Song Features&lt;/h3&gt;
&lt;p&gt;Apart from variables such as the album that a song belongs to and its date of release, Spotify’s API can give us several features that capture a song’s different audio characteristics.&lt;/p&gt;
&lt;p&gt;You can see a full list of these features in this link. However, I am only interested in some of these features, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;valence&lt;/strong&gt; measures the happiness of a song.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;energy&lt;/strong&gt; is relatively self-explanatory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tempo&lt;/strong&gt; measures the speed of a song.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;loudness&lt;/strong&gt; is also self-explanatory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;acousticness&lt;/strong&gt; identifies whether the track is acoustic&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;instrumentalness&lt;/strong&gt; shows whether a track contains no vocals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;danceability&lt;/strong&gt; determines how good a song is for dancing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jakelawlor/TidyTuesday_JL/blob/master/CodeFiles/Jan21.20.Spotify.Rmd&#34;&gt;This excellent visualization&lt;/a&gt; inspired me to create a similar plot for some of the most well-known Persian singers and see how their audio features differ from each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;artists &amp;lt;-
  c( &amp;#39;Sirvan Khosravi&amp;#39;,&amp;#39;Hesameddin Seraj&amp;#39;,&amp;#39;Rastak&amp;#39;,&amp;#39;Shahram Nazeri&amp;#39;,&amp;#39;Hossein Alizadeh&amp;#39;,&amp;#39;Reza Sadeghi&amp;#39;,&amp;#39;Alireza Eftekhari&amp;#39;,&amp;#39;Mohammadreza Shajarian&amp;#39;,
     &amp;#39;Salar Aghili&amp;#39;,&amp;#39;Morteza Pashaei&amp;#39;, &amp;#39;Alireza Ghorbani&amp;#39;,&amp;#39;Homayoun Shajarian&amp;#39;, &amp;#39;Mohsen Yeganeh&amp;#39; ,&amp;#39;Morteza Pashaei&amp;#39;,&amp;#39;Moein&amp;#39;,&amp;#39;Farzad Farzin&amp;#39;,
     &amp;#39;Babak Jahanbakhsh&amp;#39;, &amp;#39;Ehsan Khajeh Amiri&amp;#39;,&amp;#39;Siavash Ghomayshi&amp;#39;,&amp;#39;Xaniar Khosravi&amp;#39;,&amp;#39;Tohi&amp;#39; ,&amp;#39;Mohsen Chavoshi&amp;#39;,&amp;#39;Amir Tataloo&amp;#39;,
     &amp;#39;Hamed Homayoun&amp;#39;,&amp;#39;Kayhan Kalhor&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will plot the average, the minimum, and the maximum value of each feature for each singer. That gives us a good picture of how different their audio characteristics are from each other. However, we must make the right adjustments to the dataset before visualizing it:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;We need to transform the original dataset into a long-dataframe, which can be done by &lt;code&gt;pivot_longer&lt;/code&gt; from the&lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We should rescale each audio feature, otherwise, the plot would not make any sense.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;order &amp;lt;- c(
  &amp;quot;valence&amp;quot;,
  &amp;quot;energy&amp;quot;,
  &amp;quot;tempo&amp;quot;,
  &amp;quot;loudness&amp;quot;,
  &amp;quot;acousticness&amp;quot;,
  &amp;quot;instrumentalness&amp;quot;,
  &amp;quot;danceability&amp;quot;
)

scaled_features_long &amp;lt;- songs_audio_plus_pop %&amp;gt;%
  mutate_at(order, scales::rescale, to = c(0, 7)) %&amp;gt;%
  filter(!is.na(popularity)) %&amp;gt;%
  filter(artist_name %in% artists) %&amp;gt;%
  mutate(artist_name = factor(artist_name))  %&amp;gt;%
  pivot_longer(
    names_to = &amp;#39;metric&amp;#39;,
    cols = c(
      &amp;quot;valence&amp;quot;,
      &amp;quot;energy&amp;quot;,
      &amp;quot;tempo&amp;quot;,
      &amp;quot;loudness&amp;quot;,
      &amp;quot;acousticness&amp;quot;,
      &amp;quot;danceability&amp;quot;),
    values_to = &amp;#39;value&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can visualize the results for each artist. As mentioned before, I will compare artists by the minimum (red), the average (orange), and maximum (yellow) values of each audio feature in their songs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  ### This plots the average of each audio feature
  geom_polygon(
    data = scaled_features_long %&amp;gt;%  group_by(artist_name, metric) %&amp;gt;%
      summarise_at(c(&amp;quot;value&amp;quot;), mean) %&amp;gt;%
      arrange(factor(metric, levels = order)) %&amp;gt;%
      ungroup(),
    aes(x = metric, y = value, group = artist_name,),
    alpha = .54,
    size = 1.5,
    show.legend = T,
    fill = &amp;#39;#FF1654&amp;#39;
  ) +
  ### This plots the maximum of each audio feature
  geom_polygon(
    data = scaled_features_long %&amp;gt;%  group_by(artist_name, metric) %&amp;gt;%
      summarise_at(c(&amp;quot;value&amp;quot;), max) %&amp;gt;%
      arrange(factor(metric, levels = order)) %&amp;gt;%
      ungroup(),
    aes(x = metric, y = value, group = artist_name,),
    alpha = .44,
    size = 1.5,
    show.legend = T,
    fill = &amp;#39;#FFE066&amp;#39;
  ) +
  ### This plots the mimumn of each audio feature
  geom_polygon(
    data = scaled_features_long %&amp;gt;%  group_by(artist_name, metric) %&amp;gt;%
      summarise_at(c(&amp;quot;value&amp;quot;), min) %&amp;gt;%
      arrange(factor(metric, levels = order)) %&amp;gt;%
      ungroup(),
    aes(x = metric, y = value, group = artist_name,),
    alpha = .84,
    size = 1.5,
    show.legend = T,
    fill =  &amp;quot;#EF476F&amp;quot;
  ) +
  scale_x_discrete(
    limits = order,
    labels = c(
      &amp;quot;Happy&amp;quot;,
      &amp;quot;Energy&amp;quot;,
      &amp;quot;Fast&amp;quot;,
      &amp;quot;Loud&amp;quot;,
      &amp;quot;Acoustic&amp;quot;,
      &amp;quot;Instrumental&amp;quot;,
      &amp;quot;Danceable&amp;quot;
    )
  ) +
  coord_polar(clip = &amp;#39;off&amp;#39;) +
  theme_minimal() +
  labs(title = &amp;quot;Persian Singers and Their Audio Characteristics&amp;quot;,
       caption = &amp;#39;Source: Spotify \n Visualization: mcnakhaee&amp;#39;) +
  ylim(0, 8) +
  facet_wrap( ~ artist_name, ncol = 4) +
  theme(
    axis.title = element_blank(),
    axis.ticks = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(
      family =  &amp;#39;Montserrat&amp;#39;,
      size = 13.5,
      margin = ggplot2::margin(30, 0, 20, 0)
    ),
    plot.caption = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 11,
      color = &amp;#39;grey80&amp;#39;
    ) ,
    text = element_text(family =  &amp;#39;Montserrat&amp;#39;),
    strip.text = element_text(family =  &amp;#39;Montserrat&amp;#39;, size = 18),
    strip.text.x = element_text(margin = ggplot2::margin(1, 1, 1, 1, &amp;quot;cm&amp;quot;)),
    panel.spacing = unit(3.5, &amp;quot;lines&amp;quot;),
    panel.grid = element_blank(),
    plot.title = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      hjust = .5,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 32,
      color = &amp;#39;gray10&amp;#39;
    )
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;2112&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;looking-more-closely-at-each-audio-feature&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Looking more closely at each audio feature&lt;/h3&gt;
&lt;p&gt;My first plot is informative, but it only gives us an overall picture of audio features. However, I would like to have a more detailed picture of singers and the audio features for each of their songs. For this reason, I will also make a separate plot for each audio feature where every song and its corresponding feature values are shown. I will also mark a few popular songs from each artist with a different color on this plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set a custom theme for our plots
theme_set(theme_void() +
  theme(
    text = element_text(family =  &amp;#39;Montserrat&amp;#39;),
    axis.text.x = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      color = &amp;#39;gray80&amp;#39;,
      size = 18
    ),
    axis.text.y = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 20),
      color = &amp;#39;gray80&amp;#39;,
      size = 20
    ),
    axis.title.x = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 22,
      color = &amp;#39;gray80&amp;#39;
    ),
    plot.title = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      hjust = .5,
      margin = ggplot2::margin(40, 0, 40, 0),
      size = 35,
      color = &amp;#39;gray80&amp;#39;
    ),
    plot.caption = element_text(family =&amp;#39;Montserrat&amp;#39;,
                                  margin = ggplot2::margin(30, 0, 20, 20),
                                      size = 20,
                                  color = &amp;#39;gray70&amp;#39;) ,
    legend.position = &amp;#39;none&amp;#39;,
    plot.background = element_rect(fill = &amp;quot;#516869&amp;quot;)
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again here, I will change the dataset to make it ready for visualization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter &amp;lt;- songs_audio_plus_pop %&amp;gt;% 
  filter(artist_name %in% artists) %&amp;gt;% 
  mutate(is_popular = !is.na(popularity)) %&amp;gt;%
  distinct(artist_name,track_name,.keep_all = T) %&amp;gt;% 
  mutate(is_popular_size = if_else(!is.na(popularity),popularity,25),
         is_popular_alpha = if_else(!is.na(popularity),0.8,0.5)) %&amp;gt;% 
  mutate(track_name= str_wrap(track_name, width = 15)) %&amp;gt;% 
  mutate(popular_track_name = if_else(!is.na(track_name_farsi)&amp;amp; !is.na(popularity) &amp;amp; nchar(track_name) &amp;lt; 20 &amp;amp; !explicit,track_name,&amp;#39;&amp;#39;)) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;happiness&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Happiness&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter %&amp;gt;%
  ggplot(aes(x = artist_name, y = valence)) +
  geom_jitter(
    aes(
      color = is_popular,
      size = is_popular_size,
      alpha = is_popular_alpha
    ),
    size = 6,
    width = 0.2,
  ) +
  geom_text_repel(
    aes(label = popular_track_name , x = artist_name , y = valence),
    family = &amp;#39;Montserrat&amp;#39;,
    color = &amp;#39;gray99&amp;#39;,
    size = 5,
    force = 0.6,
    max.iter = 2000,
    box.padding = 0.4,
    point.padding = 0.6,
    min.segment.length = 0.15,
    nudge_y      = 0.001,
    hjust = 0.5,
    segment.alpha = 0.6,
    segment.size = 0.6
  ) +
  stat_summary(
    fun = mean,
    geom = &amp;#39;point&amp;#39;,
    color = &amp;#39;#FF9F1C&amp;#39;,
    size = 5,
    aes(group = artist_name)) +
  scale_color_manual(values = c(&amp;#39;#FFD166&amp;#39;, &amp;#39;#EF476F&amp;#39;)) +
  scale_y_continuous(sec.axis = dup_axis()) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;energy&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Energy&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter %&amp;gt;%
  ggplot(aes(x = artist_name, y = energy)) +
  geom_jitter(
    aes(
      color = is_popular,
      size = is_popular_size,
      alpha = is_popular_alpha
    ),
    size = 6,
    width = 0.2,
  ) +
  geom_text_repel(
    aes(label = popular_track_name , x = artist_name , y = energy),
    family = &amp;#39;Montserrat&amp;#39;,
    color = &amp;#39;gray90&amp;#39;,
    size = 6,
    force = 0.6,
    max.iter = 2000,
    box.padding = 0.4,
    point.padding = 0.6,
    min.segment.length = 0.15,
    nudge_y      = 0.001,
    hjust = 0.5,
    segment.alpha = 0.6,
    segment.size = 0.6
  ) +
  stat_summary(
    fun = mean,
    geom = &amp;#39;point&amp;#39;,
    color = &amp;#39;#FF9F1C&amp;#39;,
    size = 5,
    aes(group = artist_name)
  ) +
  scale_color_manual(values = c(&amp;#39;#EF476F&amp;#39;, &amp;#39;#EF476F&amp;#39;)) +
  scale_y_continuous(sec.axis = dup_axis()) +
  coord_flip() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;acousticness&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acousticness&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter %&amp;gt;%
  ggplot(aes(x = artist_name, y = acousticness)) +
  geom_jitter(
    aes(
      color = is_popular,
      size = is_popular_size,
      alpha = is_popular_alpha
    ),
    size = 6,
    width = 0.2,
  ) +
  geom_text_repel(
    aes(label = popular_track_name , x = artist_name , y = acousticness),
    family = &amp;#39;Montserrat&amp;#39;,
    color = &amp;#39;gray90&amp;#39;,
    size = 6,
    force = 0.6,
    max.iter = 2000,
    box.padding = 0.4,
    point.padding = 0.6,
    min.segment.length = 0.15,
    nudge_y      = 0.001,
    hjust = 0.5,
    segment.alpha = 0.6,
    segment.size = 0.6
  ) +
  stat_summary(
    fun = mean,
    geom = &amp;#39;point&amp;#39;,
    color = &amp;#39;#FF9F1C&amp;#39;,
    size = 5,
    aes(group = artist_name)
  ) +
  scale_color_manual(values = c(&amp;#39;#118AB2&amp;#39;, &amp;#39;#06D6A0&amp;#39;)) +
  scale_y_continuous(sec.axis = dup_axis()) +
  coord_flip() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;danceability&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Danceability&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter %&amp;gt;%
  ggplot(aes(x = artist_name, y = danceability)) +
  geom_jitter(
    aes(
      color = is_popular,
      size = is_popular_size,
      alpha = is_popular_alpha
    ),
    size = 6,
    width = 0.2,
  ) +
  geom_text_repel(
    aes(label = popular_track_name , x = artist_name , y = danceability),
    family = &amp;#39;Montserrat&amp;#39;,
    color = &amp;#39;gray90&amp;#39;,
    size = 6,
    force = 0.6,
    max.iter = 2000,
    box.padding = 0.4,
    point.padding = 0.6,
    min.segment.length = 0.15,
    nudge_y      = 0.001,
    hjust = 0.5,
    segment.alpha = 0.6,
    segment.size = 0.6
  ) +
  stat_summary(
    fun = mean,
    geom = &amp;#39;point&amp;#39;,
    color = &amp;#39;#FF9F1C&amp;#39;,
    size = 5,
    aes(group = artist_name)
  ) +
  scale_color_manual(values = c(&amp;#39;#A5668B&amp;#39;, &amp;#39;#EF476F&amp;#39;)) +
  scale_y_continuous(sec.axis = dup_axis()) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;loudness&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Loudness&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop_jitter %&amp;gt;%
  ggplot(aes(x = artist_name, y = loudness)) +
  geom_jitter(
    aes(
      color = is_popular,
      size = is_popular_size,
      alpha = is_popular_alpha
    ),
    size = 6,
    width = 0.2,
    
  ) +
  geom_text_repel(
    aes(label = popular_track_name , x = artist_name , y = loudness),
    family = &amp;#39;Montserrat&amp;#39;,
    color = &amp;#39;gray90&amp;#39;,
    size = 6,
    force = 0.6,
    max.iter = 2000,
    box.padding = 0.4,
    point.padding = 0.6,
    min.segment.length = 0.15,
    nudge_y      = 0.001,
    hjust = 0.5,
    segment.alpha = 0.6,
    segment.size = 0.6
  ) +
  stat_summary(
    fun = mean,
    geom = &amp;#39;point&amp;#39;,
    color = &amp;#39;#FF9F1C&amp;#39;,
    size = 5,
    aes(group = artist_name)
  ) +
  scale_color_manual(values = c(&amp;#39;#06D6A0&amp;#39;, &amp;#39;#EF476F&amp;#39;)) +
  scale_y_continuous(sec.axis = dup_axis()) +
  coord_flip() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;most-popular-songs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Most Popular Songs&lt;/h2&gt;
&lt;p&gt;As I mentioned previously, we can only retrieve his/her top 10 popular songs for each artist. The popularity of a track is a value between 0 (the least popular) and 100 (the most popular). Spotify uses an algorithm to calculate popularity scores, which is heavily influenced by the total number of times a song has been played recently. You can read more about it in this &lt;a href=&#34;https://developer.spotify.com/documentation/web-api/reference/tracks/get-track/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Knowing this fact about how popularity is measured, we can visualize songs and artists that have been popular and played recently.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;songs_audio_plus_pop &amp;lt;- songs_audio_plus_pop %&amp;gt;%
  filter(
    !artist_name %in% c(
      &amp;#39;Hatam Asgari&amp;#39;,
      &amp;#39;Kaveh Deylami&amp;#39;,
      &amp;#39;Nasser Abdollahi&amp;#39;,
      &amp;#39;Peyman Yazdanian&amp;#39;,
      &amp;#39;Abbas Ghaderi&amp;#39;,
      &amp;#39;Mohammad Golriz&amp;#39;,
      &amp;#39;Hamid Hami&amp;#39;,
      &amp;#39;Koveyti Poor&amp;#39;,
      &amp;#39;Mohsen Sharifian&amp;#39;,
      &amp;#39;Soheil Nafissi&amp;#39;))
songs_audio_plus_pop %&amp;gt;%
  filter(!is.na(popularity)) %&amp;gt;%
  mutate(track_name = if_else(!is.na(track_name), track_name, track_name)) %&amp;gt;%
  group_by(artist_name) %&amp;gt;%
  summarize(
    avg_pop = mean(popularity),
    min_pop = min(popularity),
    max_pop = max(popularity),
    most_popular = track_name[which.max(popularity)],
    least_popular = track_name[which.min(popularity)]
  ) %&amp;gt;%
  mutate(
    artist_name = fct_reorder(artist_name, avg_pop),
  ) %&amp;gt;%
  
  ggplot(aes(x = min_pop , xend = max_pop, y = artist_name)) +
  geom_dumbbell(
    colour_x = &amp;#39;#ef476f&amp;#39;,
    colour_xend = &amp;#39;#118ab2&amp;#39;,
    size_x = 7,
    size_xend = 7
  ) +
  geom_text(
    aes(x = min_pop - 1, y = artist_name, label = least_popular),
    size = 7,
    family = &amp;#39;Montserrat&amp;#39;,
    hjust = 1
  ) +
  geom_text(
    aes(x = max_pop + 1, y = artist_name, label = most_popular),
    size = 7,
    family = &amp;#39;Montserrat&amp;#39;,
    hjust = 0
  ) +
  scale_x_continuous(sec.axis = dup_axis()) +
  theme_tufte() +
  theme(
    plot.title = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      hjust = .5,
      margin = ggplot2::margin(0, 0, 40, 0),
      size = 45
    ),
    plot.subtitle = element_markdown(
      family = &amp;#39;Montserrat&amp;#39;,
      size = 15,
      margin = ggplot2::margin(20, 0, 40, 0),
      hjust = 1
      
    ),
    axis.text.x = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 20
    ),
    
    axis.text.y = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 20
    ),
    axis.title.x = element_text(
      family = &amp;#39;Montserrat&amp;#39;,
      margin = ggplot2::margin(30, 0, 20, 0),
      size = 30
    ),
    plot.caption = element_text(family =&amp;#39;Montserrat&amp;#39;,
                                margin = ggplot2::margin(30, 0, 20, 20),
                                size = 20,
                                color = &amp;#39;gray20&amp;#39;) ,
    axis.title.y = element_blank(),
    plot.background = element_rect(fill = &amp;#39;#FCF0E1&amp;#39;),
    plot.margin = unit(c(1, 1, 1.5, 1.2), &amp;quot;cm&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-04-happiest-saddest-most-energetic-and-fastet-persian-singers-on-spotify/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;2880&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows the most popular song and the least popular track of each artist among his top 10 songs. The artists are also sorted based on their average popularity.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Map of Spotify Songs</title>
      <link>/post/2020-02-01-the-map-of-spotify-songs/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-02-01-the-map-of-spotify-songs/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In the &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md&#34;&gt;4th week of the Tidy Tuesday project&lt;/a&gt;, a very interesting and fun dataset was proposed to the data science community. The dataset contains information about thousands of songs on Spotify’s platform and along with their metadata and audio features. You can download the dataset can using the following piece of code.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md&#34;&gt;4th week of the Tidy Tuesday project&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs &amp;lt;- readr::read_csv(&amp;#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv&amp;#39;)
head(spotify_songs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 23
##   track_id track_name track_artist track_popularity track_album_id
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         
## 1 6f807x0~ I Don&amp;#39;t C~ Ed Sheeran                 66 2oCs0DGTsRO98~
## 2 0r7CVbZ~ Memories ~ Maroon 5                   67 63rPSO264uRjW~
## 3 1z1Hg7V~ All the T~ Zara Larsson               70 1HoSmj2eLcsrR~
## 4 75Fpbth~ Call You ~ The Chainsm~               60 1nqYsOef1yKKu~
## 5 1e8PAfc~ Someone Y~ Lewis Capal~               69 7m7vv9wlQ4i0L~
## 6 7fvUMiy~ Beautiful~ Ed Sheeran                 67 2yiy9cd2QktrN~
## # ... with 18 more variables: track_album_name &amp;lt;chr&amp;gt;,
## #   track_album_release_date &amp;lt;chr&amp;gt;, playlist_name &amp;lt;chr&amp;gt;, playlist_id &amp;lt;chr&amp;gt;,
## #   playlist_genre &amp;lt;chr&amp;gt;, playlist_subgenre &amp;lt;chr&amp;gt;, danceability &amp;lt;dbl&amp;gt;,
## #   energy &amp;lt;dbl&amp;gt;, key &amp;lt;dbl&amp;gt;, loudness &amp;lt;dbl&amp;gt;, mode &amp;lt;dbl&amp;gt;, speechiness &amp;lt;dbl&amp;gt;,
## #   acousticness &amp;lt;dbl&amp;gt;, instrumentalness &amp;lt;dbl&amp;gt;, liveness &amp;lt;dbl&amp;gt;, valence &amp;lt;dbl&amp;gt;,
## #   tempo &amp;lt;dbl&amp;gt;, duration_ms &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this week’s tidy Tuesday, I decided to use a somewhat different approach from my previous submissions. Instead of focusing solely on the visualization aspect of my submissions, I tried to use other tools from the tidy model universe for machine learning model development,&lt;/p&gt;
&lt;p&gt;Each song has around 12 columns representing audio features. The Github’s page for this dataset describes these features as follows:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;19%&#34; /&gt;
&lt;col width=&#34;7%&#34; /&gt;
&lt;col width=&#34;73%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;variable&lt;/th&gt;
&lt;th&gt;class&lt;/th&gt;
&lt;th&gt;description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;danceability&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;energy&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;key&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;loudness&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;mode&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;speechiness&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;acousticness&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;instrumentalness&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;liveness&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;valence&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;tempo&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;duration_ms&lt;/td&gt;
&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;Duration of song in milliseconds&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It would be very helpful to compare songs based on their audio features and have an overall picture of where each song is placed. Unfortunately, we can only visualize 2 or 3 audio features at the same time, and It is not possible to put all these features in a 2D or 3D space. So, I tried to use unsupervised machine learning to visualize songs on a 2D space by transforming their high-dimensional audio features into a more compressed form.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidymodels)
library(workflows)
library(gghighlight)
library(hrbrthemes)
library(ggthemes)
library(lubridate)
library(reticulate)
library(ggrepel)
library(plotly)
library(uwot)


theme_update(legend.position = &amp;#39;top&amp;#39;,
   legend.text  = element_text(size = 32,color = &amp;#39;gray75&amp;#39; ),
   legend.key = element_rect(fill = &amp;quot;black&amp;quot;, color = &amp;quot;black&amp;quot;),
   legend.background= element_rect(fill = &amp;quot;black&amp;quot;, color = &amp;quot;black&amp;quot;),
   plot.title = element_text(family = &amp;#39;Montserrat&amp;#39;, face = &amp;quot;bold&amp;quot;, size = 60,hjust = 0.5,vjust = 0.5,color = &amp;#39;#FFE66D&amp;#39;,margin = ggplot2::margin(40,0,0,0)),
   plot.subtitle = element_text(
   family = &amp;#39;Montserrat&amp;#39;, size = 30, hjust = 0.5),
   strip.background = element_blank(),
   plot.background = element_rect(fill = &amp;quot;black&amp;quot;, color = &amp;quot;black&amp;quot;),
   panel.background = element_rect(fill = &amp;quot;black&amp;quot;, color = &amp;quot;black&amp;quot;),
   panel.grid.major.x =element_blank(),
   panel.grid.major.y =element_blank(),
   panel.grid.minor =element_blank(),
   axis.text.x.bottom = element_blank(),
   axis.ticks.x = element_blank(), 
   axis.ticks.y = element_blank(),
   axis.text.x = element_blank(),
   axis.text.y.left = element_blank()) &lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;dimensionality-reduction-and-umap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dimensionality Reduction and UMAP&lt;/h2&gt;
&lt;p&gt;My initial idea was to use some clustering algorithms to cluster songs based on their audio feature and find songs that are similar to each other. Yet, it was not easy to visualize these clusters in a two-dimensional space. Of course, you can do that by using hierarchal clustering but even then, visualizing a few thousand samples (songs) seems to be impractical. So, I decided to use other unsupervised techniques to compress these high-dimensional audio features and transform them into a more compact 2D space.&lt;/p&gt;
&lt;p&gt;There are several dimensionality reduction algorithms such as PCA, t-SNE UMAP. The primary purpose of these algorithms is to give us a compressed representation of the input data, while preserving the most relevant information in the data. PCA is a linear dimensionality reduction method, while both t-SNE and UMAP are non-linear methods.&lt;/p&gt;
&lt;p&gt;In this post, I will use UMAP and t-SNE, two widely used dimensionality reduction algorithms. When the input dataset is large T-SNE becomes very slow and is not an efficient algorithm anymore. On the other hand, UMAP can handle larger datasets much more easily and quickly. Moreover, UMAP can preserve the underlying local structure present in the data, and it can also represent the global structure of the data more accurately. What do we mean by local and global structure? For example, in the song dataset, persevering local structure means that songs that belong to an artist are clustered together. Similarly, global structure means that songs belonging to more related genres (e.g., hard rock, album rock, and classic rock) will be placed in close proximity to each other on the new projection.&lt;/p&gt;
&lt;p&gt;UMAP achieves this goal by employing some advanced optimization techniques and mathematical concepts. Understanding how UMAP uses these techniques and projects the input data into a more compressed representation is not crucial, but If you are curious to know more about the theory behind UMAP and its difference with T-SNE, I recommend &lt;a href=&#34;https://pair-code.github.io/understanding-umap/&#34;&gt;this excellent blogpost&lt;/a&gt; by Andy Coenen and Adam Pearce.&lt;/p&gt;
&lt;div id=&#34;data-preprocessing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Preprocessing&lt;/h3&gt;
&lt;p&gt;Both UMAP and T-SNE compute a distance metric between samples. This distance metric should be meaningful and reasonable. If we do not scale the input features before feeding them to these algorithms, some features might have a stronger (unfair) influence than other features on the computation of the distance between samples. For this reason, it is necessary to normalize input features before implementing them,&lt;/p&gt;
&lt;p&gt;I create a data preprocessing recipe using the &lt;code&gt;recipe&lt;/code&gt; package, and I add a normalization step to scale the audio features. Note that since I implement an unsupervised algorithm, there is no need to split the dataset into a training and testing dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;normalized_features &amp;lt;- spotify_songs %&amp;gt;%
 recipe() %&amp;gt;% 
 step_normalize( danceability,
  energy,
  key,
  loudness,
  mode,
  speechiness,
  acousticness,
  instrumentalness,
  liveness,
  valence,
  tempo,
  duration_ms) %&amp;gt;% 
 prep() %&amp;gt;% 
 juice()

head(normalized_features)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 23
##   track_id track_name track_artist track_popularity track_album_id
##   &amp;lt;fct&amp;gt;    &amp;lt;fct&amp;gt;      &amp;lt;fct&amp;gt;                   &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;         
## 1 6f807x0~ I Don&amp;#39;t C~ Ed Sheeran                 66 2oCs0DGTsRO98~
## 2 0r7CVbZ~ Memories ~ Maroon 5                   67 63rPSO264uRjW~
## 3 1z1Hg7V~ All the T~ Zara Larsson               70 1HoSmj2eLcsrR~
## 4 75Fpbth~ Call You ~ The Chainsm~               60 1nqYsOef1yKKu~
## 5 1e8PAfc~ Someone Y~ Lewis Capal~               69 7m7vv9wlQ4i0L~
## 6 7fvUMiy~ Beautiful~ Ed Sheeran                 67 2yiy9cd2QktrN~
## # ... with 18 more variables: track_album_name &amp;lt;fct&amp;gt;,
## #   track_album_release_date &amp;lt;fct&amp;gt;, playlist_name &amp;lt;fct&amp;gt;, playlist_id &amp;lt;fct&amp;gt;,
## #   playlist_genre &amp;lt;fct&amp;gt;, playlist_subgenre &amp;lt;fct&amp;gt;, danceability &amp;lt;dbl&amp;gt;,
## #   energy &amp;lt;dbl&amp;gt;, key &amp;lt;dbl&amp;gt;, loudness &amp;lt;dbl&amp;gt;, mode &amp;lt;dbl&amp;gt;, speechiness &amp;lt;dbl&amp;gt;,
## #   acousticness &amp;lt;dbl&amp;gt;, instrumentalness &amp;lt;dbl&amp;gt;, liveness &amp;lt;dbl&amp;gt;, valence &amp;lt;dbl&amp;gt;,
## #   tempo &amp;lt;dbl&amp;gt;, duration_ms &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;t-sne&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;T-SNE&lt;/h2&gt;
&lt;p&gt;Both UMAP and T-SNE have several hyper-parameters that can influence the resulting embedding output. However, T-SNE is a notoriously slow algorithm and the opportunity for trial and error with different sets of hyper-parameter values are limited. For the sake of simplicity, I stick to default settings for hyper-parameter in T-SNE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rtsne)
tsne_embedding &amp;lt;- normalized_features %&amp;gt;%
 select(c(12:23)) %&amp;gt;%
 Rtsne(check_duplicates = FALSE)

tsne_embeddings &amp;lt;- spotify_songs %&amp;gt;% 
 select(-c(12:22)) %&amp;gt;% 
 bind_cols(tsne_embedding$Y %&amp;gt;% as_tibble()) %&amp;gt;% = element_rect(fill = &amp;quot;black&amp;quot;, color = &amp;quot;black&amp;quot;),
 dplyr::rename(tsne_1 = V1, tsne_2 = V2) %&amp;gt;% &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though I managed to transform a high dimensional dataset into a 2D space, still it was very challenging to visualize every song and every artists all at once. So, I just select a few famous artists that I have heard about. Each artist in this list more or less represents at least a genre of music and it can perfectly show that an artist (or a band) made several genres of music and how difficult our task is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;selected_artists &amp;lt;- c(&amp;#39;Queen&amp;#39;,&amp;#39;Drake&amp;#39;,&amp;#39;Rihanna&amp;#39;,&amp;#39;Taylor Swift&amp;#39;,&amp;#39;Eminem&amp;#39;,&amp;#39;Snoop Dogg&amp;#39;,&amp;#39;Katy Perry&amp;#39;,&amp;#39;The Beatles&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tsne_embeddings &amp;lt;- tsne_embeddings%&amp;gt;% 
 mutate(
  selected_artist = if_else( track_artist %in% selected_artists, as.character(track_artist), &amp;quot;&amp;quot;),
  track_name_selected_artist = if_else(track_artist %in% selected_artists, track_name, NULL),
  genre_selected_artist = if_else(track_artist %in% selected_artists,playlist_genre, NULL),
  popular_tracks_selected_artist = if_else(
   track_artist %in% selected_artists &amp;amp; track_popularity &amp;gt; 65,shorter_names, NULL )) %&amp;gt;%
 distinct(track_name, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tsne_embeddings %&amp;gt;%
 ggplot(aes(x = tsne_1, y = tsne_2 ,color = selected_artist )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size = 0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_manual(values = c(&amp;#39;#5BC0EB&amp;#39;,&amp;#39;#FDE74C&amp;#39;,&amp;#39;#7FB800&amp;#39;,&amp;#39;#E55934&amp;#39;,&amp;#39;#FA7921&amp;#39;,&amp;#39;#1A936F&amp;#39; ,&amp;#39;#F0A6CA&amp;#39;,&amp;#39;#B8BEDD&amp;#39;))+
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 7, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    title = &amp;#39;The Map of Spotify Songs Based on T-SNE Algorithm\n&amp;#39;,
    subtitle = &amp;#39;Using the T-SNE algorithm, the audio features of each song are mapped into a 2D space.\n Each point represents a unique song and the most popular songs of several known artist are also shown\n&amp;#39;,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see in this projection, songs that belong to the same artists are placed close to each other. It seems that T-SNE is able to preserve the local topological structure of songs. Now I will look at how T-SNE distinguishes different genres of music.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tsne_embeddings %&amp;gt;%
 ggplot(aes(x = tsne_1, y = tsne_2 ,color = playlist_genre )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size = 0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_tableau() +
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 7, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    title = &amp;#39;The Map of Spotify Songs Based on T-SNE Algorithm\n&amp;#39;,
    subtitle = &amp;#39;Using the T-SNE algorithm, the audio features of each song are mapped into a 2D space.\n Each point represents a unique song and the most popular songs of several known artist are also shown\n&amp;#39;,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;umap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;UMAP&lt;/h2&gt;
&lt;p&gt;Just like t-SNE, UMAP is a dimensionality reduction algorithm but it is much more computationally efficient and faster that t-SNE. The UMAP algorithm was &lt;a href=&#34;https://github.com/lmcinnes/umap&#34;&gt;originally implemented in Python&lt;/a&gt;. But there are also several libraries in R such as &lt;a href=&#34;https://github.com/ropenscilabs/umapr&#34;&gt;umapr&lt;/a&gt;, &lt;a href=&#34;https://cran.r-project.org/web/packages/umap/vignettes/umap.html&#34;&gt;umap&lt;/a&gt; and &lt;a href=&#34;https://github.com/jlmelville/uwot&#34;&gt;uwot&lt;/a&gt; that also provide an implementation of the UMAP algorithm. &lt;a href=&#34;https://github.com/ropenscilabs/umapr&#34;&gt;&lt;code&gt;umapr&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/umap/vignettes/umap.html&#34;&gt;&lt;code&gt;umap&lt;/code&gt;&lt;/a&gt; use the &lt;a href=&#34;https://cran.r-project.org/web/packages/reticulate/index.html&#34;&gt;&lt;code&gt;reticulate&lt;/code&gt;&lt;/a&gt; package and provide a wrapper function around the original &lt;code&gt;umap-learn&lt;/code&gt; python library. Also, &lt;code&gt;umap&lt;/code&gt; and &lt;code&gt;uwot&lt;/code&gt; library have their own R implementation and they do not require the python package to be installed beforehand. For this specific experiment, I will use the &lt;code&gt;uwot&lt;/code&gt; library.&lt;/p&gt;
&lt;p&gt;we can change and tune a few hyper-parameters in the implementation of UMAP in the uwot library, These hyperparameter can change the embedding outcome. However, there are two hyper-parameters that have a much more important impact on the structure of the low-dimensional representation:&lt;code&gt;n_neighbors&lt;/code&gt;, &lt;code&gt;min_dist&lt;/code&gt; and &lt;code&gt;metric&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n_neighbors&lt;/code&gt; determines the number of nearest neighbor data points that we use to compute and construct the embedding.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_dist&lt;/code&gt; controls the minimum distance between data points in the low dimensional space (embedding). That means a low value of &lt;code&gt;min_dist&lt;/code&gt; results in a more compact clusters of data points. On the other hand, with larger values of &lt;code&gt;min_dist&lt;/code&gt;, the projection will be less compact and tend to preserve the global structure.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;metric&lt;/code&gt;: We can use different metrics (e.g.. cosine or Euclidean) to compute the distance between data points and to find the nearest neighbors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice of hyperparameter values can be very important for the final projection. However,choosing the right set of hyper-parameters in UMAP is extremely difficult because UMAP is an unsupervised algorithm and we do not have a baseline to evaluate its performance. Fortunately, UMAP is vary fast and scalable algorithm. It means that we can run UMAP with different hyperparameter settings and decide which set of values best serves our purpose.&lt;/p&gt;
&lt;p&gt;My main goal from running UMAP is to visualize songs and their audio features on a 2D space and I can use a trick to decrease UMAP’s computation time. According to uwot’s documentation, if my only purpose is visualization, I can set the value of &lt;code&gt;fast_sgd&lt;/code&gt; hyper-parameter to &lt;code&gt;TRUE&lt;/code&gt; to speed up UMAP’s convergence and running time.
Next, I create a grid of values for these three hyper-parameters and each time I will learn a new UMAP embedding based on different combinations of these values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_neighbors &amp;lt;- c(15,30,50,100,150)
min_distance &amp;lt;- c( 0.001, 0.003, 0.009,0.03,0.09)
metrics &amp;lt;- c(&amp;quot;euclidean&amp;quot; ,&amp;quot;cosine&amp;quot;,&amp;quot;hamming&amp;quot;)

#make a copy of the dataset
spotify_songs_emb &amp;lt;- spotify_songs

for (nn in n_neighbors) {
 for (md in min_distance) {
  for (metric in metrics) {
  umap_embedding &amp;lt;- normalized_features %&amp;gt;%
  select(c(12:23)) %&amp;gt;%
  umap(n_neighbors = nn,min_dist = md,metric = metric, fast_sgd = TRUE)
  spotify_songs_emb &amp;lt;- spotify_songs_emb %&amp;gt;% 
  bind_cols(umap_embedding[,1]%&amp;gt;% as_tibble() ) %&amp;gt;% 
  bind_cols(umap_embedding[,2] %&amp;gt;% as_tibble() )
  names(spotify_songs_emb)[names(spotify_songs_emb) == &amp;#39;value&amp;#39; ] = paste(&amp;#39;nn_&amp;#39;,nn,&amp;#39;md_&amp;#39;,md,&amp;#39;metric&amp;#39;,metric,&amp;#39;1&amp;#39;,sep = &amp;#39;.&amp;#39;)
  names(spotify_songs_emb)[names(spotify_songs_emb) == &amp;#39;value1&amp;#39; ] = paste(&amp;#39;nn_&amp;#39;,nn,&amp;#39;md_&amp;#39;,md,&amp;#39;metric&amp;#39;,metric,&amp;#39;2&amp;#39;,sep = &amp;#39;.&amp;#39;)
  }
 }
 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like what I did for T-SNE, I will focus on the same list of artists.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb &amp;lt;- spotify_songs_emb%&amp;gt;% 
 mutate(
  selected_artist = if_else( track_artist %in% selected_artists, as.character(track_artist), &amp;quot;&amp;quot;),
  point_size_selected_artist = if_else(track_artist %in% selected_artists, 0.5, 0.1),
  track_name_selected_artist = if_else(track_artist %in% selected_artists, track_name, NULL),
  genre_selected_artist = if_else(track_artist %in% selected_artists,playlist_genre, NULL),
  popular_tracks_selected_artist = if_else(
   track_artist %in% selected_artists &amp;amp; track_popularity &amp;gt; 65,shorter_names, NULL )) %&amp;gt;%
 distinct(track_name, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it was time to plot the results of UMAP embeddings using &lt;code&gt;ggplot&lt;/code&gt; and &lt;a href=&#34;https://github.com/yutannihilation/gghighlight&#34;&gt;&lt;code&gt;gghighlight&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;setting-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 1&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 50&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.09&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Euclidean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.50.md_.0.09.metric.euclidean.1, y = nn_.50.md_.0.09.metric.euclidean.2 ,color = selected_artist )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_manual(values = c(&amp;#39;#5BC0EB&amp;#39;,&amp;#39;#FDE74C&amp;#39;,&amp;#39;#7FB800&amp;#39;,&amp;#39;#E55934&amp;#39;,&amp;#39;#FA7921&amp;#39;,&amp;#39;#1A936F&amp;#39; ,&amp;#39;#F0A6CA&amp;#39;,&amp;#39;#B8BEDD&amp;#39;))+
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 50&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.09&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Hamming&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.50.md_.0.09.metric.hamming.1, y = nn_.50.md_.0.09.metric.hamming.2,color = selected_artist )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_manual(values = c(&amp;#39;#5BC0EB&amp;#39;,&amp;#39;#FDE74C&amp;#39;,&amp;#39;#7FB800&amp;#39;,&amp;#39;#E55934&amp;#39;,&amp;#39;#FA7921&amp;#39;,&amp;#39;#1A936F&amp;#39; ,&amp;#39;#F0A6CA&amp;#39;,&amp;#39;#B8BEDD&amp;#39;))+
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 150&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.09&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Euclidean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.150.md_.0.09.metric.euclidean.1, y = nn_.150.md_.0.09.metric.euclidean.2,color = playlist_genre )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_tableau() +
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 4&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 15&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.09&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Euclidean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.15.md_.0.09.metric.euclidean.1, y = nn_.15.md_.0.09.metric.euclidean.2,color = playlist_genre )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_tableau() +
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 5&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 150&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.001&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Euclidean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.150.md_.0.001.metric.euclidean.1, y = nn_.150.md_.0.001.metric.euclidean.2,color = playlist_genre )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_tableau() +
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-6&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting 6&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nearest neighbors: 15&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Minimum distance: 0.09&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance metric: Hamming&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs_emb %&amp;gt;%
 ggplot(aes(x = nn_.15.md_.0.09.metric.hamming.1, y = nn_.15.md_.0.09.metric.hamming.2,color = playlist_genre )) +
 geom_point(size = 5.3,alpha =0.8) +
 gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size=0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
 scale_color_tableau() +
 guides(size = FALSE,
  color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
  geom_text_repel(aes(label = popular_tracks_selected_artist),size = 8, family = &amp;#39;Montserrat&amp;#39;,
  point.padding = 2.2,
  box.padding = .5,
  force = 1,
  min.segment.length = 0.1) +
 labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
    color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the most part, both t-SNE and UMAP place songs from the same artists or similar songs close to each other. The UMAP embeddings with Euclidean distance are somehow similar to a real map. In the UMAP representation of the songs, we can see isolated clusters of songs. However, in t-SNE representation, no clear and separate cluster of points can be seen.
We can observe that the most influential hyper-parameter seems to be the distance metric. Additionally, when we decrease the value of &lt;code&gt;min_dist&lt;/code&gt;, the projection becomes less compact, and the global structure emerges. However, we also see that sometimes music genres are not well-separated as we would like them to be. We should take into account that audio features might not be enough to distinguish between genres of music, and We need to incorporate other aspects of songs such as lyrics to differentiate between genres. For instance, Kaylin Pavlik, in her blogpost explained how she based on similar audio features, trained several machine learning models to classify songs into six main categories (EDM, Latin, Pop, R&amp;amp;B, Rap, &amp;amp; Rock). Her best model achieved an accuracy of 54.3%, which is a decent performance but not super accurate. I also tuned and trained a few machine learning models on this dataset, but I could not achieve higher performance.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;supervised-umap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Supervised UMAP&lt;/h2&gt;
&lt;p&gt;UMAP is an unsupervised dimensionality reduction algorithm, but we can also feed target labels to UMAP and make it a &lt;a href=&#34;https://umap-learn.readthedocs.io/en/latest/supervised.html&#34;&gt;supervised algorithm&lt;/a&gt; by specifying the target variable. To make this happen in UWOT, we can give the target column (playlist_genre) as an input to &lt;code&gt;y&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;supervised_umap_embedding_df &amp;lt;- 
  spotify_songs %&amp;gt;% 
  select(-c(12:22)) %&amp;gt;% 
  bind_cols(supervised_umap_embedding %&amp;gt;% as_tibble()) %&amp;gt;% 
  dplyr::rename(umap_1 = V1, umap_2 = V2) %&amp;gt;% 
  mutate(
    selected_artist = if_else( track_artist %in% selected_artists, as.character(track_artist), &amp;quot;&amp;quot;),
    point_size_selected_artist = if_else(track_artist %in% selected_artists, 0.5, 0.1),
    track_name_selected_artist = if_else(track_artist %in% selected_artists, track_name, NULL),
    genre_selected_artist = if_else(track_artist %in% selected_artists,playlist_genre, NULL),
    popular_tracks_selected_artist = if_else(
      track_artist %in% selected_artists &amp;amp; track_popularity &amp;gt; 70,shorter_names, NULL )) %&amp;gt;%
  distinct(track_name, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;supervised_umap_embedding_df %&amp;gt;%
  ggplot(aes(x = umap_1, y = umap_2 ,color = playlist_genre )) +
  geom_point(size = 5.3,alpha =0.8 ) +
  gghighlight(selected_artist != &amp;quot;&amp;quot;,unhighlighted_params = list(alpha = 0.3,size = 0.8, color = &amp;#39;#FFE66D&amp;#39;)) +
  scale_color_tableau() +
  guides(size = FALSE,
    color = guide_legend(override.aes = list(alpha = 0.9,size = 12))) +
    geom_text_repel(aes(label = popular_tracks_selected_artist),size = 7, family = &amp;#39;Montserrat&amp;#39;,
    point.padding = 2.2,
    box.padding = .5,
    force = 1,
    min.segment.length = 0.1) +
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot; ,
       color = &amp;#39;&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-01-the-map-of-spotify-songs/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;3360&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is no surprise that the results of the supervised UMAP are much better separated than the unsupervised one. We just gave additional information to UMAP to transform input data.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
